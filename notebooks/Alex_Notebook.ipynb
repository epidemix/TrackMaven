{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_json('https://s3.amazonaws.com/temp-data-pulls/newdump.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', -1)\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.mode.chained_assignment = None\n",
    "rawpin_blog = df[(df[\"type\"]==\"pin\") | (df[\"type\"]==\"blog post\")]\n",
    "rawpin_blog.drop([\"has_spend\"], axis = 1, inplace=True)\n",
    "channel_info = rawpin_blog['channel_info'].apply(pd.Series)\n",
    "channel_info.columns = [\"channel\", \"info\"]\n",
    "content_info = rawpin_blog['content'].apply(pd.Series)\n",
    "content_info.drop(['author_email', 'content', 'pinned_from'], axis=1, inplace=True) ## THESE HAVE ONLY NULLS\n",
    "for x in content_info.columns:\n",
    "    if \"count\" in x:\n",
    "        content_info[x].fillna(np.NaN, inplace = True)\n",
    "        #content_info[x] = content_info[x].astype(int)\n",
    "master_pinblog = rawpin_blog.join(channel_info).join(content_info)\n",
    "master_pinblog.drop(['channel_info', 'content'], axis = 1, inplace = True)\n",
    "master_pinblog.columns = ['brand', 'engagement', 'uniqueid', 'impact', 'share_token', 'timestamp',\n",
    "       'type', 'urls', 'channel', 'info', 'author_name', 'comment_count',\n",
    "       'description', 'fb_likecount', 'fb_sharecount',\n",
    "       'gplus_count', 'hashtags', 'image_url', 'like_count',\n",
    "       'link', 'linkedin_sharecount', 'links', 'pin_id', 'pin_url',\n",
    "       'pin_count', 'post_type', 'repin_count', 'summary',\n",
    "       'thumbnail_url', 'title', 'tweet_count']\n",
    "\n",
    "master_pinblog[\"links_count\"] = master_pinblog['links'].str.len()\n",
    "df_new = master_pinblog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_new = master_pinblog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new.link = df_new.link.astype(str)\n",
    "df_new.link.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['glamour' 'teenvogue' 'wmagazine' 'allure' 'cntraveler'\n",
      " 'architecturaldigest' 'vogue']\n",
      "['glamour']\n"
     ]
    }
   ],
   "source": [
    "# create new df called blogs that only contains blogs\n",
    "blogs = df_new[df_new.type == 'blog post']\n",
    "blogs.reset_index(inplace = True)\n",
    "\n",
    "#create new df for pinterest\n",
    "pins = df_new[df_new.type == 'pin']\n",
    "pins.reset_index(inplace = True)\n",
    "\n",
    "# converts link to string so we can split\n",
    "blogs.link = blogs.link.astype(str)\n",
    "# instantiate a new list called new_mag\n",
    "new_mag = []\n",
    "# list comprehension that just keeps part before '.com'\n",
    "# we can use list comprehension because this is true for all values\n",
    "magazine = [i.split('.com')[0] for i in blogs.link]\n",
    "# start for loop to get rid of everything before the name of the magazine\n",
    "for i in magazine:\n",
    "    if '.' in i:\n",
    "        new_mag.append(i.split('.')[1])\n",
    "# if there isn't a '.' it just sends the existing name to the list\n",
    "    else:\n",
    "        new_mag.append(i)\n",
    "# create new column for the blog df with the publications\n",
    "blogs['pub'] = new_mag\n",
    "\n",
    "# create a new subset of dataframes based on publication\n",
    "df_blogs_glamour = blogs[blogs.pub == 'glamour']\n",
    "#df_pins_glamour = pins[pins.pub == 'glamour']\n",
    "df_blogs_teenvogue = blogs[blogs.pub == 'teenvogue']\n",
    "#df_pins_teenvogue = pins[pins.pub == 'teenvogue']\n",
    "df_blogs_wmagazine = blogs[blogs.pub == 'wmagazine']\n",
    "#df_pins_wmagazine = pins[pins.pub == 'wmagazine']\n",
    "df_blogs_allure = blogs[blogs.pub == 'allure']\n",
    "#df_pins_allure = pins[pins.pub == 'allure']\n",
    "df_blogs_cntraveler = blogs[blogs.pub == 'cntraveler']\n",
    "#df_pins_cntraveler = pins[pins.pub == 'cntraveler']\n",
    "df_blogs_architecturaldigest = blogs[blogs.pub == 'architecturaldigest']\n",
    "#df_pins_architecturaldigest = pins[pins.pub == 'architecturaldigest']\n",
    "df_blogs_vogue = blogs[blogs.pub == 'vogue']\n",
    "#df_pins_vogue = pins[pins.pub == 'vogue']\n",
    "\n",
    "print(blogs.pub.unique())\n",
    "print(df_blogs_glamour.pub.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tokenizer = word_tokenize\n",
    "blog_title_tokens = [tokenizer(i) for i in blogs.title]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"'Riverdale\",\n",
       " \"'\",\n",
       " 'Season',\n",
       " '2',\n",
       " 'Episode',\n",
       " '6',\n",
       " 'Recap',\n",
       " ':',\n",
       " 'Who',\n",
       " 'Is',\n",
       " 'the',\n",
       " 'Sugar',\n",
       " 'Man',\n",
       " '?']"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blog_title_tokens[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# extract title length\n",
    "#working on this\n",
    "#blogs['title_length'] = [len(i) for i in blogs.title]\n",
    "#pins['title_length'] = [len(i) for i in pins.description]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from stop_words import get_stop_words\n",
    "from nltk import word_tokenize\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from gensim import corpora, models\n",
    "import gensim\n",
    "import pyLDAvis.gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "glamour\n",
      "teenvogue\n",
      "wmagazine\n",
      "allure\n",
      "cntraveler\n",
      "architecturaldigest\n",
      "vogue\n"
     ]
    }
   ],
   "source": [
    "for i in blogs.pub.unique():\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stemming(pdseries):\n",
    "    stemmer = SnowballStemmer(\"english\",ignore_stopwords=True)\n",
    "    en_stop = get_stop_words('en')\n",
    "    # when a word is stemmed, contractions are rightfully turned into different stems since 's = is\n",
    "    # however, in reality, all of those words are themselves stop words, so I want to exclude them\n",
    "    # question marks and the like are not helpful for our purpose of figuring out potential categories\n",
    "    contractions = [\"'s\",\"s\",\"'\",\".\",\",\",\"n't\",\"'d\",\"ll\",\"re\",\"ve\",\"``\",\n",
    "                    \"''\",\"”\",\"“\",\"’\",\"(\",\")\",\"?\",\":\",\"t\",\";\",\"d\",\"!\",\"-\",\"[\",\"]\",\"w\",\"#\",\"m\"]\n",
    "    #other_words = [\"new\",\"get\",]\n",
    "    # list for tokenized documents in loop\n",
    "    texts = []\n",
    "\n",
    "    # loop through document list\n",
    "    post_text = [i for i in pdseries]\n",
    "    count = 1\n",
    "    print(f\"Initializing tokenizer and stemmer ...\")\n",
    "    print(\"Number of posts tokenized and stemmed:\")\n",
    "    for i in post_text:\n",
    "        # clean and tokenize document string\n",
    "        raw = i.lower()\n",
    "        tokens = word_tokenize(raw)\n",
    "\n",
    "        # stem tokens and remove stop words\n",
    "        stemmed_tokens = [stemmer.stem(i) for i in tokens if not i in en_stop]\n",
    "\n",
    "        #remove stemmed contractions\n",
    "        contracted_tokens = [i for i in stemmed_tokens if not i in contractions]\n",
    "\n",
    "        # add tokens to list\n",
    "        texts.append(contracted_tokens)\n",
    "        if count % 5000 == 0:\n",
    "            print(count)\n",
    "        count += 1\n",
    "    print(\"Stemming Completed.\")\n",
    "    return texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lemmatizing(pdseries):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    en_stop = get_stop_words('en')\n",
    "    # when a word is stemmed, contractions are rightfully turned into different stems since 's = is\n",
    "    # however, in reality, all of those words are themselves stop words, so I want to exclude them\n",
    "    # question marks and the like are not helpful for our purpose of figuring out potential categories\n",
    "    contractions = [\"'s\",\"s\",\"'\",\".\",\",\",\"n't\",\"'d\",\"ll\",\"re\",\"ve\",\"``\",\n",
    "                    \"''\",\"”\",\"“\",\"’\",\"(\",\")\",\"?\",\":\",\"t\",\";\",\"d\",\"!\",\"-\",\"[\",\"]\",\"w\",\"#\",\"m\"]\n",
    "    #other_words = [\"new\",\"get\",]\n",
    "    # list for tokenized documents in loop\n",
    "    texts = []\n",
    "\n",
    "    # loop through document list\n",
    "    post_text = [i for i in pdseries]\n",
    "    count = 1\n",
    "    print(f\"Initializing tokenizer and lemmatizer ...\")\n",
    "    print(\"Number of posts tokenized and lemmatized:\")\n",
    "    for i in post_text:\n",
    "        # clean and tokenize document string\n",
    "        raw = i.lower()\n",
    "        tokens = word_tokenize(raw)\n",
    "\n",
    "        # stem tokens and remove stop words\n",
    "        lemmed_tokens = [lemmatizer.lemmatize(i) for i in tokens if not i in en_stop]\n",
    "\n",
    "        #remove stemmed contractions\n",
    "        contracted_tokens = [i for i in lemmed_tokens if not i in contractions]\n",
    "\n",
    "        # add tokens to list\n",
    "        texts.append(contracted_tokens)\n",
    "        if count % 5000 == 0:\n",
    "            print(count)\n",
    "        count += 1\n",
    "    print(\"Lemmatizing Completed.\")\n",
    "    return texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing tokenizer and lemmatizer ...\n",
      "Number of posts tokenized and lemmatized:\n",
      "5000\n",
      "10000\n",
      "Lemmatizing Completed.\n",
      "Initializing tokenizer and lemmatizer ...\n",
      "Number of posts tokenized and lemmatized:\n",
      "5000\n",
      "10000\n",
      "15000\n",
      "20000\n",
      "25000\n",
      "Lemmatizing Completed.\n",
      "Initializing tokenizer and lemmatizer ...\n",
      "Number of posts tokenized and lemmatized:\n",
      "5000\n",
      "Lemmatizing Completed.\n",
      "Initializing tokenizer and lemmatizer ...\n",
      "Number of posts tokenized and lemmatized:\n",
      "5000\n",
      "Lemmatizing Completed.\n",
      "Initializing tokenizer and lemmatizer ...\n",
      "Number of posts tokenized and lemmatized:\n",
      "5000\n",
      "Lemmatizing Completed.\n",
      "Initializing tokenizer and lemmatizer ...\n",
      "Number of posts tokenized and lemmatized:\n",
      "Lemmatizing Completed.\n",
      "Initializing tokenizer and lemmatizer ...\n",
      "Number of posts tokenized and lemmatized:\n",
      "5000\n",
      "10000\n",
      "Lemmatizing Completed.\n"
     ]
    }
   ],
   "source": [
    "glamour = lemmatizing(df_blogs_glamour.title)\n",
    "teenvogue = lemmatizing(df_blogs_teenvogue.title)\n",
    "wmagazine = lemmatizing(df_blogs_wmagazine.title)\n",
    "allure = lemmatizing(df_blogs_allure.title)\n",
    "cntraveler = lemmatizing(df_blogs_cntraveler.title)\n",
    "architecturaldigest = lemmatizing(df_blogs_architecturaldigest.title)\n",
    "vogue = lemmatizing(df_blogs_vogue.title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "def topic_modeling(pub,number_of_topics = 5,number_of_words = 30,number_of_passes = 1):\n",
    "    print(\"Initializing:...\")\n",
    "    # turn our tokenized documents into a id <-> term dictionary\n",
    "    dictionary = corpora.Dictionary(pub)\n",
    "    # convert tokenized documents into a document-term matrix\n",
    "    corpus = [dictionary.doc2bow(text) for text in pub]\n",
    "    # generate LDA model\n",
    "    print(\"Generating Model...\")\n",
    "    ldamodel = gensim.models.ldamodel.LdaModel(corpus, num_topics=number_of_topics, id2word = dictionary, passes=number_of_passes)\n",
    "    topics = ldamodel.print_topics(num_topics=number_of_topics, num_words=number_of_words)\n",
    "    print(\"Topics\\n\")\n",
    "    for i in range(number_of_topics):\n",
    "        print(f\"Topic {topics[i][0]}: \\n\")\n",
    "        print(topics[i][1], \"\\n\")\n",
    "    return ldamodel[corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "***GLAMOUR***\n",
      "Initializing:...\n",
      "Generating Model...\n",
      "Topics\n",
      "\n",
      "Topic 0: \n",
      "\n",
      "0.014*\"jenner\" + 0.013*\"kardashian\" + 0.010*\"just\" + 0.009*\"new\" + 0.009*\"kim\" + 0.008*\"kylie\" + 0.008*\"hair\" + 0.008*\"taylor\" + 0.007*\"swift\" + 0.007*\"kendall\" + 0.007*\"work\" + 0.006*\"look\" + 0.006*\"instagram\" + 0.005*\"like\" + 0.005*\"photo\" + 0.005*\"tatum\" + 0.004*\"secret\" + 0.004*\"made\" + 0.004*\"'m\" + 0.003*\"now\" + 0.003*\"lip\" + 0.003*\"video\" + 0.003*\"say\" + 0.003*\"style\" + 0.003*\"woman\" + 0.003*\"jennifer\" + 0.003*\"back\" + 0.003*\"girl\" + 0.003*\"west\" + 0.003*\"pretty\" \n",
      "\n",
      "Topic 1: \n",
      "\n",
      "0.017*\"woman\" + 0.012*\"season\" + 0.007*\"recap\" + 0.006*\"game\" + 0.006*\"new\" + 0.006*\"throne\" + 0.005*\"episode\" + 0.005*\"just\" + 0.005*\"get\" + 0.005*\"real\" + 0.005*\"fan\" + 0.005*\"2\" + 0.004*\"theory\" + 0.004*\"will\" + 0.004*\"6\" + 0.004*\"much\" + 0.004*\"sex\" + 0.004*\"7\" + 0.004*\"big\" + 0.004*\"2016\" + 0.004*\"star\" + 0.003*\"u\" + 0.003*\"way\" + 0.003*\"girl\" + 0.003*\"relationship\" + 0.003*\"job\" + 0.003*\"love\" + 0.003*\"reveal\" + 0.003*\"bang\" + 0.003*\"bachelorette\" \n",
      "\n",
      "Topic 2: \n",
      "\n",
      "0.024*\"best\" + 0.019*\"2016\" + 0.017*\"summer\" + 0.009*\"woman\" + 0.009*\"makeup\" + 0.006*\"hair\" + 0.006*\"new\" + 0.006*\"celebrity\" + 0.006*\"make\" + 0.005*\"look\" + 0.005*\"day\" + 0.005*\"sex\" + 0.005*\"red\" + 0.005*\"beauty\" + 0.005*\"like\" + 0.005*\"get\" + 0.005*\"2017\" + 0.005*\"idea\" + 0.004*\"will\" + 0.004*\"gala\" + 0.004*\"award\" + 0.004*\"met\" + 0.004*\"tattoo\" + 0.004*\"10\" + 0.004*\"carpet\" + 0.004*\"really\" + 0.004*\"teigen\" + 0.004*\"chrissy\" + 0.004*\"dress\" + 0.004*\"year\" \n",
      "\n",
      "Topic 3: \n",
      "\n",
      "0.017*\"trump\" + 0.011*\"donald\" + 0.009*\"clinton\" + 0.008*\"hadid\" + 0.008*\"hillary\" + 0.008*\"new\" + 0.007*\"show\" + 0.007*\"obama\" + 0.006*\"woman\" + 0.006*\"watch\" + 0.006*\"first\" + 0.006*\"just\" + 0.005*\"video\" + 0.005*\"gigi\" + 0.005*\"netflix\" + 0.004*\"taylor\" + 0.004*\"2016\" + 0.004*\"swift\" + 0.004*\"can\" + 0.003*\"love\" + 0.003*\"bella\" + 0.003*\"president\" + 0.003*\"michelle\" + 0.003*\"dream\" + 0.003*\"house\" + 0.003*\"disney\" + 0.003*\"life\" + 0.003*\"sexual\" + 0.003*\"lady\" + 0.003*\"will\" \n",
      "\n",
      "Topic 4: \n",
      "\n",
      "0.012*\"new\" + 0.010*\"wedding\" + 0.009*\"wear\" + 0.009*\"fashion\" + 0.009*\"trend\" + 0.008*\"$\" + 0.007*\"way\" + 0.007*\"now\" + 0.007*\"can\" + 0.006*\"fall\" + 0.006*\"dress\" + 0.006*\"get\" + 0.006*\"need\" + 0.006*\"right\" + 0.006*\"thing\" + 0.006*\"outfit\" + 0.005*\"know\" + 0.005*\"home\" + 0.005*\"selena\" + 0.005*\"gomez\" + 0.005*\"will\" + 0.005*\"spring\" + 0.005*\"show\" + 0.005*\"kate\" + 0.004*\"see\" + 0.004*\"hair\" + 0.004*\"5\" + 0.004*\"ring\" + 0.004*\"beauty\" + 0.004*\"engagement\" \n",
      "\n",
      "Adding topic probabilities to DataFrame...\n",
      "Number of Missing Values:\n",
      "0\n",
      "\n",
      "***TEENVOGUE***\n",
      "Initializing:...\n",
      "Generating Model...\n",
      "Topics\n",
      "\n",
      "Topic 0: \n",
      "\n",
      "0.011*\"—\" + 0.009*\"know\" + 0.008*\"need\" + 0.008*\"jonas\" + 0.008*\"girl\" + 0.007*\"emma\" + 0.007*\"thing\" + 0.007*\"demi\" + 0.007*\"lovato\" + 0.006*\"new\" + 0.006*\"just\" + 0.006*\"go\" + 0.006*\"viral\" + 0.005*\"nick\" + 0.005*\"photo\" + 0.004*\"grace\" + 0.004*\"actually\" + 0.004*\"10\" + 0.004*\"instagram\" + 0.004*\"watch\" + 0.004*\"woman\" + 0.004*\"season\" + 0.004*\"watson\" + 0.004*\"video\" + 0.004*\"teen\" + 0.004*\"say\" + 0.004*\"now\" + 0.004*\"2\" + 0.004*\"shawn\" + 0.004*\"mendes\" \n",
      "\n",
      "Topic 1: \n",
      "\n",
      "0.017*\"taylor\" + 0.016*\"new\" + 0.016*\"swift\" + 0.009*\"harry\" + 0.008*\"prom\" + 0.007*\"style\" + 0.007*\"video\" + 0.007*\"music\" + 0.007*\"instagram\" + 0.006*\"cyrus\" + 0.006*\"miley\" + 0.006*\"just\" + 0.006*\"watch\" + 0.006*\"wear\" + 0.006*\"winter\" + 0.006*\"cara\" + 0.005*\"met\" + 0.005*\"cover\" + 0.005*\"delevingne\" + 0.005*\"medium\" + 0.005*\"top\" + 0.005*\"vogue\" + 0.005*\"finally\" + 0.005*\"kardashian\" + 0.004*\"social\" + 0.004*\"will\" + 0.004*\"way\" + 0.004*\"lady\" + 0.004*\"gala\" + 0.004*\"potter\" \n",
      "\n",
      "Topic 2: \n",
      "\n",
      "0.012*\"school\" + 0.010*\"new\" + 0.010*\"trump\" + 0.010*\"student\" + 0.008*\"clinton\" + 0.008*\"college\" + 0.007*\"hillary\" + 0.007*\"woman\" + 0.007*\"black\" + 0.007*\"high\" + 0.006*\"donald\" + 0.006*\"teen\" + 0.006*\"trailer\" + 0.005*\"will\" + 0.005*\"‘\" + 0.004*\"sexual\" + 0.004*\"watch\" + 0.004*\"university\" + 0.004*\"girl\" + 0.004*\"hudgens\" + 0.004*\"vanessa\" + 0.004*\"make\" + 0.004*\"say\" + 0.004*\"assault\" + 0.004*\"way\" + 0.003*\"white\" + 0.003*\"—\" + 0.003*\"transgender\" + 0.003*\"lawrence\" + 0.003*\"jennifer\" \n",
      "\n",
      "Topic 3: \n",
      "\n",
      "0.029*\"jenner\" + 0.023*\"2016\" + 0.021*\"best\" + 0.019*\"hadid\" + 0.018*\"kendall\" + 0.016*\"kylie\" + 0.015*\"gigi\" + 0.014*\"fashion\" + 0.011*\"award\" + 0.010*\"wear\" + 0.009*\"hair\" + 0.009*\"10\" + 0.008*\"beauty\" + 0.007*\"bella\" + 0.007*\"new\" + 0.007*\"look\" + 0.007*\"celebrity\" + 0.006*\"show\" + 0.006*\"red\" + 0.006*\"see\" + 0.006*\"week\" + 0.005*\"dress\" + 0.005*\"trump\" + 0.005*\"carpet\" + 0.005*\"photo\" + 0.004*\"idea\" + 0.004*\"wore\" + 0.004*\"hailey\" + 0.004*\"$\" + 0.004*\"baldwin\" \n",
      "\n",
      "Topic 4: \n",
      "\n",
      "0.022*\"new\" + 0.014*\"justin\" + 0.014*\"bieber\" + 0.013*\"selena\" + 0.013*\"gomez\" + 0.012*\"zayn\" + 0.011*\"—\" + 0.010*\"just\" + 0.009*\"hair\" + 0.009*\"malik\" + 0.009*\"little\" + 0.009*\"one\" + 0.007*\"video\" + 0.007*\"song\" + 0.006*\"music\" + 0.006*\"movie\" + 0.006*\"ariana\" + 0.006*\"grande\" + 0.005*\"makeup\" + 0.005*\"show\" + 0.005*\"instagram\" + 0.005*\"every\" + 0.005*\"direction\" + 0.005*\"will\" + 0.005*\"7\" + 0.004*\"liar\" + 0.004*\"tv\" + 0.004*\"single\" + 0.004*\"back\" + 0.004*\"super\" \n",
      "\n",
      "Adding topic probabilities to DataFrame...\n",
      "Number of Missing Values:\n",
      "1\n",
      "\n",
      "***WMAGAZINE***\n",
      "Initializing:...\n",
      "Generating Model...\n",
      "Topics\n",
      "\n",
      "Topic 0: \n",
      "\n",
      "0.012*\"art\" + 0.010*\"twitter\" + 0.010*\"trump\" + 0.010*\"nyfw\" + 0.009*\"news\" + 0.009*\"inside\" + 0.008*\"$\" + 0.006*\"men\" + 0.006*\"weekend\" + 0.006*\"white\" + 0.006*\"bowie\" + 0.006*\"performance\" + 0.006*\"good\" + 0.006*\"party\" + 0.005*\"michael\" + 0.005*\"celebrity\" + 0.005*\"school\" + 0.005*\"pajama\" + 0.005*\"donald\" + 0.005*\"fit\" + 0.005*\"actual\" + 0.005*\"blue\" + 0.005*\"swim\" + 0.005*\"delight\" + 0.005*\"put\" + 0.005*\"remembrance\" + 0.005*\"brace\" + 0.005*\"mia\" + 0.005*\"saoirse\" + 0.005*\"ronan\" \n",
      "\n",
      "Topic 1: \n",
      "\n",
      "0.023*\"golden\" + 0.020*\"globe\" + 0.018*\"red\" + 0.014*\"carpet\" + 0.011*\"beauty\" + 0.011*\"hollywood\" + 0.009*\"girl\" + 0.009*\"jennifer\" + 0.008*\"jacob\" + 0.008*\"marc\" + 0.007*\"look\" + 0.007*\"tale\" + 0.007*\"public\" + 0.007*\"shine\" + 0.007*\"best\" + 0.006*\"bosworth\" + 0.006*\"know\" + 0.006*\"fashion\" + 0.006*\"2017\" + 0.006*\"kate\" + 0.006*\"day\" + 0.006*\"10\" + 0.006*\"need\" + 0.006*\"get\" + 0.005*\"wear\" + 0.005*\"cool\" + 0.005*\"buy\" + 0.005*\"fall\" + 0.005*\"dress\" + 0.005*\"everything\" \n",
      "\n",
      "Topic 2: \n",
      "\n",
      "0.015*\"fashion\" + 0.015*\"new\" + 0.013*\"best\" + 0.012*\"show\" + 0.010*\"couture\" + 0.010*\"week\" + 0.010*\"model\" + 0.009*\"beauty\" + 0.008*\"delevingne\" + 0.008*\"cara\" + 0.007*\"hadid\" + 0.007*\"style\" + 0.007*\"talk\" + 0.007*\"party\" + 0.006*\"waterhouse\" + 0.006*\"sarah\" + 0.006*\"suki\" + 0.006*\"london\" + 0.006*\"jenner\" + 0.005*\"girl\" + 0.005*\"smith\" + 0.005*\"2017\" + 0.005*\"meet\" + 0.005*\"spring\" + 0.005*\"york\" + 0.005*\"chanel\" + 0.005*\"runway\" + 0.005*\"french\" + 0.005*\"face\" + 0.004*\"kanye\" \n",
      "\n",
      "Topic 3: \n",
      "\n",
      "0.025*\"2016\" + 0.012*\"new\" + 0.008*\"kirsten\" + 0.008*\"dunst\" + 0.008*\"rosie\" + 0.008*\"slip\" + 0.008*\"february\" + 0.007*\"fashion\" + 0.007*\"time\" + 0.006*\"west\" + 0.006*\"kanye\" + 0.006*\"album\" + 0.006*\"gwyneth\" + 0.006*\"best\" + 0.005*\"paltrow\" + 0.005*\"kardashian\" + 0.005*\"alicia\" + 0.005*\"york\" + 0.005*\"reveals\" + 0.005*\"vikander\" + 0.005*\"club\" + 0.005*\"robert\" + 0.005*\"pink\" + 0.005*\"playing\" + 0.005*\"paul\" + 0.005*\"pregnant\" + 0.005*\"meet\" + 0.005*\"david\" + 0.005*\"bright\" + 0.004*\"lover\" \n",
      "\n",
      "Topic 4: \n",
      "\n",
      "0.016*\"cate\" + 0.013*\"david\" + 0.012*\"oscar\" + 0.012*\"blanchett\" + 0.011*\"look\" + 0.011*\"like\" + 0.009*\"new\" + 0.008*\"nomination\" + 0.008*\"model\" + 0.007*\"bowie\" + 0.006*\"art\" + 0.006*\"movie\" + 0.005*\"brie\" + 0.005*\"chloë\" + 0.005*\"wear\" + 0.005*\"larson\" + 0.005*\"grace\" + 0.005*\"jonathan\" + 0.005*\"ever\" + 0.005*\"embrace\" + 0.005*\"celebrity\" + 0.005*\"prada\" + 0.005*\"according\" + 0.005*\"america\" + 0.004*\"time\" + 0.004*\"slimane\" + 0.004*\"war\" + 0.004*\"hedi\" + 0.004*\"lima\" + 0.004*\"portrait\" \n",
      "\n",
      "Adding topic probabilities to DataFrame...\n",
      "Number of Missing Values:\n",
      "4\n",
      "\n",
      "***ALLURE***\n",
      "Initializing:...\n",
      "Generating Model...\n",
      "Topics\n",
      "\n",
      "Topic 0: \n",
      "\n",
      "0.022*\"beauty\" + 0.020*\"makeup\" + 0.017*\"skin\" + 0.012*\"hair\" + 0.011*\"product\" + 0.009*\"secret\" + 0.008*\"best\" + 0.008*\"according\" + 0.007*\"hack\" + 0.007*\"look\" + 0.007*\"see\" + 0.007*\"woman\" + 0.007*\"artist\" + 0.006*\"allure\" + 0.006*\"need\" + 0.006*\"new\" + 0.006*\"one\" + 0.006*\"every\" + 0.006*\"day\" + 0.005*\"editor\" + 0.005*\"fashion\" + 0.005*\"5\" + 0.005*\"get\" + 0.005*\"7\" + 0.005*\"3\" + 0.005*\"thing\" + 0.005*\"drugstore\" + 0.005*\"know\" + 0.004*\"week\" + 0.004*\"victoria\" \n",
      "\n",
      "Topic 1: \n",
      "\n",
      "0.016*\"2016\" + 0.014*\"jenner\" + 0.011*\"beauty\" + 0.008*\"hadid\" + 0.008*\"hair\" + 0.007*\"kylie\" + 0.007*\"new\" + 0.006*\"kendall\" + 0.006*\"best\" + 0.006*\"kat\" + 0.006*\"make\" + 0.006*\"routine\" + 0.006*\"body\" + 0.006*\"von\" + 0.006*\"newest\" + 0.005*\"&\" + 0.005*\"hairstylist\" + 0.005*\"will\" + 0.005*\"collection\" + 0.005*\"review\" + 0.005*\"model\" + 0.005*\"us\" + 0.005*\"get\" + 0.004*\"look\" + 0.004*\"skin-care\" + 0.004*\"woman\" + 0.004*\"product\" + 0.004*\"bella\" + 0.004*\"gigi\" + 0.004*\"celebrity\" \n",
      "\n",
      "Topic 2: \n",
      "\n",
      "0.017*\"beauty\" + 0.014*\"new\" + 0.013*\"hair\" + 0.009*\"makeup\" + 0.009*\"product\" + 0.008*\"look\" + 0.007*\"mask\" + 0.007*\"award\" + 0.006*\"trick\" + 0.006*\"2017\" + 0.006*\"best\" + 0.006*\"easy\" + 0.005*\"way\" + 0.005*\"just\" + 0.005*\"face\" + 0.005*\"making\" + 0.004*\"favorite\" + 0.004*\"one\" + 0.004*\"instagram\" + 0.004*\"chrissy\" + 0.004*\"braid\" + 0.004*\"'re\" + 0.004*\"get\" + 0.004*\"trend\" + 0.004*\"finally\" + 0.004*\"swears\" + 0.003*\"thing\" + 0.003*\"give\" + 0.003*\"music\" + 0.003*\"teigen\" \n",
      "\n",
      "Topic 3: \n",
      "\n",
      "0.012*\"hair\" + 0.008*\"internet\" + 0.008*\"new\" + 0.007*\"just\" + 0.007*\"woman\" + 0.007*\"red\" + 0.006*\"eye\" + 0.006*\"like\" + 0.006*\"trend\" + 0.006*\"one\" + 0.006*\"spring\" + 0.006*\"dress\" + 0.005*\"get\" + 0.005*\"jennifer\" + 0.005*\"look\" + 0.005*\"wear\" + 0.004*\"girl\" + 0.004*\"wore\" + 0.004*\"make\" + 0.004*\"will\" + 0.004*\"ca\" + 0.004*\"love\" + 0.004*\"men\" + 0.004*\"study\" + 0.004*\"carpet\" + 0.004*\"oscar\" + 0.003*\"show\" + 0.003*\"really\" + 0.003*\"way\" + 0.003*\"skin\" \n",
      "\n",
      "Topic 4: \n",
      "\n",
      "0.019*\"new\" + 0.015*\"makeup\" + 0.012*\"lip\" + 0.011*\"lipstick\" + 0.010*\"beauty\" + 0.009*\"best\" + 0.008*\"palette\" + 0.008*\"eye\" + 0.008*\"just\" + 0.008*\"look\" + 0.008*\"collection\" + 0.007*\"kardashian\" + 0.007*\"instagram\" + 0.007*\"hair\" + 0.006*\"make\" + 0.006*\"kylie\" + 0.006*\"can\" + 0.006*\"need\" + 0.006*\"nail\" + 0.006*\"2017\" + 0.006*\"product\" + 0.005*\"now\" + 0.005*\"faced\" + 0.005*\"see\" + 0.005*\"m.a.c\" + 0.005*\"cosmetic\" + 0.005*\"kit\" + 0.005*\"$\" + 0.005*\"kim\" + 0.005*\"will\" \n",
      "\n",
      "Adding topic probabilities to DataFrame...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Missing Values:\n",
      "0\n",
      "\n",
      "***CNTRAVELER***\n",
      "Initializing:...\n",
      "Generating Model...\n",
      "Topics\n",
      "\n",
      "Topic 0: \n",
      "\n",
      "0.050*\"flight\" + 0.035*\"$\" + 0.030*\"deal\" + 0.021*\"day\" + 0.019*\"u.s.\" + 0.011*\"round-trip\" + 0.010*\"airline\" + 0.009*\"fly\" + 0.007*\"plane\" + 0.007*\"get\" + 0.007*\"world\" + 0.006*\"new\" + 0.006*\"australia\" + 0.006*\"weekend\" + 0.006*\"air\" + 0.005*\"perfect\" + 0.005*\"jetblue\" + 0.005*\"city\" + 0.005*\"europe\" + 0.004*\"free\" + 0.004*\"may\" + 0.004*\"passport\" + 0.004*\"jet\" + 0.004*\"50\" + 0.004*\"airway\" + 0.004*\"cuba\" + 0.004*\"paris\" + 0.003*\"british\" + 0.003*\"island\" + 0.003*\"attendant\" \n",
      "\n",
      "Topic 1: \n",
      "\n",
      "0.028*\"hotel\" + 0.024*\"world\" + 0.022*\"new\" + 0.018*\"best\" + 0.016*\"now\" + 0.009*\"cruise\" + 0.009*\"2016\" + 0.008*\"list\" + 0.007*\"right\" + 0.007*\"can\" + 0.007*\"restaurant\" + 0.007*\"hot\" + 0.006*\"around\" + 0.006*\"art\" + 0.006*\"london\" + 0.006*\"favorite\" + 0.006*\"eat\" + 0.005*\"city\" + 0.005*\"2017\" + 0.005*\"food\" + 0.005*\"nyc\" + 0.004*\"inside\" + 0.004*\"recipe\" + 0.004*\"airbnb\" + 0.004*\"york\" + 0.004*\"airplane\" + 0.004*\"room\" + 0.004*\"will\" + 0.004*\"book\" + 0.004*\"ship\" \n",
      "\n",
      "Topic 2: \n",
      "\n",
      "0.020*\"travel\" + 0.009*\"new\" + 0.008*\"park\" + 0.008*\"fashion\" + 0.008*\"week\" + 0.007*\"travelogue\" + 0.007*\"podcast\" + 0.007*\"take\" + 0.007*\"chef\" + 0.007*\"national\" + 0.006*\"watch\" + 0.006*\"global\" + 0.006*\"best\" + 0.006*\"airline\" + 0.005*\"make\" + 0.005*\"gold\" + 0.005*\"get\" + 0.004*\"summer\" + 0.004*\"see\" + 0.004*\"air\" + 0.004*\"young\" + 0.004*\"photo\" + 0.004*\"'ll\" + 0.004*\"plane\" + 0.004*\"2017\" + 0.004*\"cocktail\" + 0.004*\"never\" + 0.004*\"want\" + 0.004*\"visiting\" + 0.003*\"traveling\" \n",
      "\n",
      "Topic 3: \n",
      "\n",
      "0.037*\"best\" + 0.018*\"world\" + 0.016*\"10\" + 0.016*\"new\" + 0.012*\"place\" + 0.011*\"beautiful\" + 0.010*\"will\" + 0.010*\"trip\" + 0.009*\"beach\" + 0.008*\"travel\" + 0.008*\"city\" + 0.007*\"make\" + 0.007*\"airport\" + 0.007*\"visit\" + 0.007*\"u.s\" + 0.006*\"hotel\" + 0.005*\"thing\" + 0.004*\"summer\" + 0.004*\"open\" + 0.004*\"go\" + 0.004*\"europe\" + 0.004*\"train\" + 0.004*\"photo\" + 0.004*\"spot\" + 0.004*\"see\" + 0.004*\"paris\" + 0.004*\"america\" + 0.004*\"way\" + 0.004*\"museum\" + 0.004*\"resort\" \n",
      "\n",
      "Topic 4: \n",
      "\n",
      "0.017*\"travel\" + 0.013*\"2016\" + 0.011*\"vacation\" + 0.008*\"airport\" + 0.007*\"american\" + 0.007*\"traveler\" + 0.007*\"know\" + 0.006*\"10\" + 0.006*\"new\" + 0.006*\"will\" + 0.006*\"trip\" + 0.006*\"like\" + 0.005*\"cruise\" + 0.005*\"9\" + 0.005*\"year\" + 0.005*\"stay\" + 0.005*\"need\" + 0.005*\"now\" + 0.005*\"plan\" + 0.004*\"pack\" + 0.004*\"time\" + 0.004*\"go\" + 0.004*\"one\" + 0.004*\"romantic\" + 0.004*\"u.s.\" + 0.003*\"avoid\" + 0.003*\"passport\" + 0.003*\"story\" + 0.003*\"security\" + 0.003*\"5\" \n",
      "\n",
      "Adding topic probabilities to DataFrame...\n",
      "Number of Missing Values:\n",
      "0\n",
      "\n",
      "***ARCHITECTURALDIGEST***\n",
      "Initializing:...\n",
      "Generating Model...\n",
      "Topics\n",
      "\n",
      "Topic 0: \n",
      "\n",
      "0.018*\"home\" + 0.018*\"5\" + 0.009*\"best\" + 0.009*\"design\" + 0.009*\"designer\" + 0.008*\"12\" + 0.007*\"garden\" + 0.007*\"summer\" + 0.007*\"color\" + 0.007*\"way\" + 0.006*\"inside\" + 0.006*\"new\" + 0.006*\"stylish\" + 0.006*\"6\" + 0.006*\"building\" + 0.005*\"look\" + 0.005*\"see\" + 0.005*\"exhibition\" + 0.005*\"4\" + 0.005*\"art\" + 0.005*\"paint\" + 0.005*\"thing\" + 0.005*\"world\" + 0.004*\"fashion\" + 0.004*\"beautiful\" + 0.004*\"know\" + 0.004*\"hotel\" + 0.004*\"secret\" + 0.004*\"&\" + 0.004*\"idea\" \n",
      "\n",
      "Topic 1: \n",
      "\n",
      "0.023*\"new\" + 0.016*\"design\" + 0.011*\"room\" + 0.010*\"york\" + 0.010*\"7\" + 0.008*\"10\" + 0.007*\"home\" + 0.007*\"art\" + 0.007*\"hotel\" + 0.007*\"apartment\" + 0.006*\"city\" + 0.006*\"ad\" + 0.005*\"museum\" + 0.005*\"designer\" + 0.005*\"modern\" + 0.005*\"idea\" + 0.005*\"behind\" + 0.005*\"will\" + 0.005*\"scene\" + 0.005*\"best\" + 0.005*\"host\" + 0.005*\"favorite\" + 0.005*\"building\" + 0.004*\"top\" + 0.004*\"world\" + 0.004*\"outdoor\" + 0.004*\"milan\" + 0.004*\"kitchen\" + 0.004*\"tokyo\" + 0.004*\"architect\" \n",
      "\n",
      "Topic 2: \n",
      "\n",
      "0.019*\"$\" + 0.019*\"million\" + 0.015*\"new\" + 0.014*\"home\" + 0.012*\"house\" + 0.008*\"tour\" + 0.007*\"next\" + 0.006*\"design\" + 0.005*\"inside\" + 0.005*\"york\" + 0.005*\"6\" + 0.005*\"hill\" + 0.005*\"5\" + 0.005*\"weekend\" + 0.005*\"getaway\" + 0.005*\"kitchen\" + 0.005*\"l.a.\" + 0.004*\"idea\" + 0.004*\"take\" + 0.004*\"will\" + 0.004*\"decor\" + 0.004*\"apartment\" + 0.004*\"renovation\" + 0.004*\"room\" + 0.004*\"get\" + 0.004*\"architecture\" + 0.004*\"beverly\" + 0.004*\"villa\" + 0.004*\"innovative\" + 0.003*\"hudson\" \n",
      "\n",
      "Topic 3: \n",
      "\n",
      "0.025*\"home\" + 0.019*\"new\" + 0.011*\"york\" + 0.009*\"style\" + 0.009*\"$\" + 0.009*\"million\" + 0.008*\"world\" + 0.008*\"design\" + 0.008*\"city\" + 0.007*\"guide\" + 0.007*\"tour\" + 0.006*\"11\" + 0.006*\"like\" + 0.006*\"house\" + 0.006*\"room\" + 0.005*\"apartment\" + 0.005*\"art\" + 0.005*\"california\" + 0.005*\"will\" + 0.005*\"bar\" + 0.005*\"every\" + 0.004*\"los\" + 0.004*\"angeles\" + 0.004*\"inside\" + 0.004*\"7\" + 0.004*\"idea\" + 0.004*\"summer\" + 0.004*\"4\" + 0.004*\"perfect\" + 0.004*\"manhattan\" \n",
      "\n",
      "Topic 4: \n",
      "\n",
      "0.038*\"$\" + 0.033*\"million\" + 0.017*\"home\" + 0.013*\"inside\" + 0.010*\"new\" + 0.009*\"house\" + 0.008*\"suite\" + 0.008*\"hotel\" + 0.008*\"look\" + 0.006*\"former\" + 0.006*\"california\" + 0.006*\"open\" + 0.005*\"just\" + 0.005*\"estate\" + 0.005*\"first\" + 0.005*\"go\" + 0.005*\"design\" + 0.005*\"apartment\" + 0.005*\"beach\" + 0.004*\"cocktail\" + 0.004*\"manhattan\" + 0.004*\"penthouse\" + 0.004*\"miami\" + 0.004*\"can\" + 0.004*\"expensive\" + 0.004*\"selling\" + 0.004*\"york\" + 0.004*\"market\" + 0.003*\"one\" + 0.003*\"west\" \n",
      "\n",
      "Adding topic probabilities to DataFrame...\n",
      "Number of Missing Values:\n",
      "0\n",
      "\n",
      "***VOGUE***\n",
      "Initializing:...\n",
      "Generating Model...\n",
      "Topics\n",
      "\n",
      "Topic 0: \n",
      "\n",
      "0.034*\"best\" + 0.023*\"2016\" + 0.022*\"week\" + 0.020*\"beauty\" + 0.019*\"10\" + 0.015*\"look\" + 0.014*\"fashion\" + 0.014*\"style\" + 0.013*\"thing\" + 0.013*\"know\" + 0.012*\"show\" + 0.009*\"5\" + 0.009*\"street\" + 0.009*\"fall\" + 0.008*\"new\" + 0.007*\"men\" + 0.007*\"hadid\" + 0.006*\"spring\" + 0.006*\"year\" + 0.005*\"need\" + 0.005*\"7\" + 0.005*\"instagrams\" + 0.005*\"moment\" + 0.005*\"take\" + 0.005*\"gigi\" + 0.005*\"winter\" + 0.005*\"hair\" + 0.004*\"girl\" + 0.004*\"vogue\" + 0.004*\"bowie\" \n",
      "\n",
      "Topic 1: \n",
      "\n",
      "0.014*\"new\" + 0.007*\"home\" + 0.006*\"can\" + 0.006*\"wedding\" + 0.005*\"world\" + 0.005*\"5\" + 0.005*\"inside\" + 0.005*\"lady\" + 0.005*\"take\" + 0.005*\"now\" + 0.004*\"dress\" + 0.004*\"fashion\" + 0.004*\"$\" + 0.004*\"wear\" + 0.004*\"way\" + 0.004*\"wave\" + 0.004*\"time\" + 0.004*\"every\" + 0.004*\"london\" + 0.004*\"woman\" + 0.004*\"biggest\" + 0.003*\"shop\" + 0.003*\"chic\" + 0.003*\"gaga\" + 0.003*\"story\" + 0.003*\"just\" + 0.003*\"get\" + 0.003*\"wardrobe\" + 0.003*\"meet\" + 0.003*\"designer\" \n",
      "\n",
      "Topic 2: \n",
      "\n",
      "0.012*\"kendall\" + 0.011*\"jenner\" + 0.010*\"model\" + 0.007*\"day\" + 0.007*\"vogue\" + 0.007*\"look\" + 0.007*\"kate\" + 0.006*\"secret\" + 0.006*\"star\" + 0.005*\"runway\" + 0.005*\"hair\" + 0.005*\"fashion\" + 0.005*\"style\" + 0.004*\"instagram\" + 0.004*\"meet\" + 0.004*\"will\" + 0.004*\"editor\" + 0.004*\"stewart\" + 0.004*\"kristen\" + 0.004*\"selena\" + 0.004*\"gomez\" + 0.004*\"like\" + 0.004*\"take\" + 0.003*\"boot\" + 0.003*\"male\" + 0.003*\"karlie\" + 0.003*\"inside\" + 0.003*\"dicaprio\" + 0.003*\"interior\" + 0.003*\"watch\" \n",
      "\n",
      "Topic 3: \n",
      "\n",
      "0.017*\"red\" + 0.016*\"carpet\" + 0.013*\"globe\" + 0.011*\"golden\" + 0.009*\"new\" + 0.009*\"west\" + 0.008*\"style\" + 0.007*\"inside\" + 0.006*\"kardashian\" + 0.006*\"girl\" + 0.005*\"fashion\" + 0.005*\"kim\" + 0.005*\"saint\" + 0.004*\"laurent\" + 0.004*\"beauty\" + 0.004*\"kanye\" + 0.004*\"2016\" + 0.004*\"obama\" + 0.004*\"look\" + 0.003*\"woman\" + 0.003*\"secret\" + 0.003*\"&\" + 0.003*\"oscar\" + 0.003*\"party\" + 0.003*\"love\" + 0.003*\"win\" + 0.003*\"dress\" + 0.003*\"get\" + 0.003*\"alexander\" + 0.003*\"kid\" \n",
      "\n",
      "Topic 4: \n",
      "\n",
      "0.040*\"new\" + 0.013*\"york\" + 0.012*\"fashion\" + 0.007*\"week\" + 0.006*\"model\" + 0.006*\"gala\" + 0.006*\"collection\" + 0.005*\"row\" + 0.005*\"hair\" + 0.005*\"host\" + 0.005*\"met\" + 0.005*\"front\" + 0.005*\"2016\" + 0.005*\"dinner\" + 0.005*\"inside\" + 0.005*\"vogue\" + 0.005*\"city\" + 0.004*\"show\" + 0.004*\"look\" + 0.004*\"oscar\" + 0.004*\"year\" + 0.004*\"fall\" + 0.004*\"make\" + 0.004*\"way\" + 0.004*\"video\" + 0.004*\"pre-fall\" + 0.004*\"first\" + 0.004*\"meet\" + 0.004*\"star\" + 0.003*\"runway\" \n",
      "\n",
      "Adding topic probabilities to DataFrame...\n",
      "Number of Missing Values:\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n***GLAMOUR***\")\n",
    "topic_vector = topic_modeling(glamour,number_of_passes = 3)\n",
    "print(\"Adding topic probabilities to DataFrame...\")\n",
    "df_blogs_glamour['Topic_0'] = [topic_vector[i][0][1] if len(topic_vector[i]) == 5 else np.NaN for i in range(len(topic_vector))]\n",
    "df_blogs_glamour['Topic_1'] = [topic_vector[i][1][1] if len(topic_vector[i]) == 5 else np.NaN for i in range(len(topic_vector))]\n",
    "df_blogs_glamour['Topic_2'] = [topic_vector[i][2][1] if len(topic_vector[i]) == 5 else np.NaN for i in range(len(topic_vector))]\n",
    "df_blogs_glamour['Topic_3'] = [topic_vector[i][3][1] if len(topic_vector[i]) == 5 else np.NaN for i in range(len(topic_vector))]\n",
    "df_blogs_glamour['Topic_4'] = [topic_vector[i][4][1] if len(topic_vector[i]) == 5 else np.NaN for i in range(len(topic_vector))]\n",
    "print(\"Number of Missing Values:\")\n",
    "print(df_blogs_glamour.Topic_4.isnull().sum())\n",
    "\n",
    "print(\"\\n***TEENVOGUE***\")\n",
    "topic_vector = topic_modeling(teenvogue,number_of_passes = 3)\n",
    "print(\"Adding topic probabilities to DataFrame...\")\n",
    "df_blogs_teenvogue['Topic_0'] = [topic_vector[i][0][1] if len(topic_vector[i]) == 5 else np.NaN for i in range(len(topic_vector))]\n",
    "df_blogs_teenvogue['Topic_1'] = [topic_vector[i][1][1] if len(topic_vector[i]) == 5 else np.NaN for i in range(len(topic_vector))]\n",
    "df_blogs_teenvogue['Topic_2'] = [topic_vector[i][2][1] if len(topic_vector[i]) == 5 else np.NaN for i in range(len(topic_vector))]\n",
    "df_blogs_teenvogue['Topic_3'] = [topic_vector[i][3][1] if len(topic_vector[i]) == 5 else np.NaN for i in range(len(topic_vector))]\n",
    "df_blogs_teenvogue['Topic_4'] = [topic_vector[i][4][1] if len(topic_vector[i]) == 5 else np.NaN for i in range(len(topic_vector))]\n",
    "print(\"Number of Missing Values:\")\n",
    "print(df_blogs_teenvogue.Topic_4.isnull().sum())\n",
    "\n",
    "print(\"\\n***WMAGAZINE***\")\n",
    "topic_vector = topic_modeling(wmagazine,number_of_passes = 3)\n",
    "print(\"Adding topic probabilities to DataFrame...\")\n",
    "df_blogs_wmagazine['Topic_0'] = [topic_vector[i][0][1] if len(topic_vector[i]) == 5 else np.NaN for i in range(len(topic_vector))]\n",
    "df_blogs_wmagazine['Topic_1'] = [topic_vector[i][1][1] if len(topic_vector[i]) == 5 else np.NaN for i in range(len(topic_vector))]\n",
    "df_blogs_wmagazine['Topic_2'] = [topic_vector[i][2][1] if len(topic_vector[i]) == 5 else np.NaN for i in range(len(topic_vector))]\n",
    "df_blogs_wmagazine['Topic_3'] = [topic_vector[i][3][1] if len(topic_vector[i]) == 5 else np.NaN for i in range(len(topic_vector))]\n",
    "df_blogs_wmagazine['Topic_4'] = [topic_vector[i][4][1] if len(topic_vector[i]) == 5 else np.NaN for i in range(len(topic_vector))]\n",
    "print(\"Number of Missing Values:\")\n",
    "print(df_blogs_wmagazine.Topic_4.isnull().sum())\n",
    "\n",
    "print(\"\\n***ALLURE***\")\n",
    "topic_vector = topic_modeling(allure,number_of_passes = 3)\n",
    "print(\"Adding topic probabilities to DataFrame...\")\n",
    "df_blogs_allure['Topic_0'] = [topic_vector[i][0][1] if len(topic_vector[i]) == 5 else np.NaN for i in range(len(topic_vector))]\n",
    "df_blogs_allure['Topic_1'] = [topic_vector[i][1][1] if len(topic_vector[i]) == 5 else np.NaN for i in range(len(topic_vector))]\n",
    "df_blogs_allure['Topic_2'] = [topic_vector[i][2][1] if len(topic_vector[i]) == 5 else np.NaN for i in range(len(topic_vector))]\n",
    "df_blogs_allure['Topic_3'] = [topic_vector[i][3][1] if len(topic_vector[i]) == 5 else np.NaN for i in range(len(topic_vector))]\n",
    "df_blogs_allure['Topic_4'] = [topic_vector[i][4][1] if len(topic_vector[i]) == 5 else np.NaN for i in range(len(topic_vector))]\n",
    "print(\"Number of Missing Values:\")\n",
    "print(df_blogs_allure.Topic_4.isnull().sum())\n",
    "\n",
    "print(\"\\n***CNTRAVELER***\")\n",
    "topic_vector = topic_modeling(cntraveler,number_of_passes = 3)\n",
    "print(\"Adding topic probabilities to DataFrame...\")\n",
    "df_blogs_cntraveler['Topic_0'] = [topic_vector[i][0][1] if len(topic_vector[i]) == 5 else np.NaN for i in range(len(topic_vector))]\n",
    "df_blogs_cntraveler['Topic_1'] = [topic_vector[i][1][1] if len(topic_vector[i]) == 5 else np.NaN for i in range(len(topic_vector))]\n",
    "df_blogs_cntraveler['Topic_2'] = [topic_vector[i][2][1] if len(topic_vector[i]) == 5 else np.NaN for i in range(len(topic_vector))]\n",
    "df_blogs_cntraveler['Topic_3'] = [topic_vector[i][3][1] if len(topic_vector[i]) == 5 else np.NaN for i in range(len(topic_vector))]\n",
    "df_blogs_cntraveler['Topic_4'] = [topic_vector[i][4][1] if len(topic_vector[i]) == 5 else np.NaN for i in range(len(topic_vector))]\n",
    "print(\"Number of Missing Values:\")\n",
    "print(df_blogs_cntraveler.Topic_4.isnull().sum())\n",
    "\n",
    "print(\"\\n***ARCHITECTURALDIGEST***\")\n",
    "topic_vector = topic_modeling(architecturaldigest,number_of_passes = 3)\n",
    "print(\"Adding topic probabilities to DataFrame...\")\n",
    "df_blogs_architecturaldigest['Topic_0'] = [topic_vector[i][0][1] if len(topic_vector[i]) == 5 else np.NaN for i in range(len(topic_vector))]\n",
    "df_blogs_architecturaldigest['Topic_1'] = [topic_vector[i][1][1] if len(topic_vector[i]) == 5 else np.NaN for i in range(len(topic_vector))]\n",
    "df_blogs_architecturaldigest['Topic_2'] = [topic_vector[i][2][1] if len(topic_vector[i]) == 5 else np.NaN for i in range(len(topic_vector))]\n",
    "df_blogs_architecturaldigest['Topic_3'] = [topic_vector[i][3][1] if len(topic_vector[i]) == 5 else np.NaN for i in range(len(topic_vector))]\n",
    "df_blogs_architecturaldigest['Topic_4'] = [topic_vector[i][4][1] if len(topic_vector[i]) == 5 else np.NaN for i in range(len(topic_vector))]\n",
    "print(\"Number of Missing Values:\")\n",
    "print(df_blogs_architecturaldigest.Topic_4.isnull().sum())\n",
    "\n",
    "print(\"\\n***VOGUE***\")\n",
    "topic_vector = topic_modeling(vogue,number_of_passes = 3)\n",
    "print(\"Adding topic probabilities to DataFrame...\")\n",
    "df_blogs_vogue['Topic_0'] = [topic_vector[i][0][1] if len(topic_vector[i]) == 5 else np.NaN for i in range(len(topic_vector))]\n",
    "df_blogs_vogue['Topic_1'] = [topic_vector[i][1][1] if len(topic_vector[i]) == 5 else np.NaN for i in range(len(topic_vector))]\n",
    "df_blogs_vogue['Topic_2'] = [topic_vector[i][2][1] if len(topic_vector[i]) == 5 else np.NaN for i in range(len(topic_vector))]\n",
    "df_blogs_vogue['Topic_3'] = [topic_vector[i][3][1] if len(topic_vector[i]) == 5 else np.NaN for i in range(len(topic_vector))]\n",
    "df_blogs_vogue['Topic_4'] = [topic_vector[i][4][1] if len(topic_vector[i]) == 5 else np.NaN for i in range(len(topic_vector))]\n",
    "print(\"Number of Missing Values:\")\n",
    "print(df_blogs_vogue.Topic_4.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Alexander/anaconda/lib/python3.6/site-packages/pyLDAvis/_prepare.py:387: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n",
      "  topic_term_dists = topic_term_dists.ix[topic_order]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.css\">\n",
       "\n",
       "\n",
       "<div id=\"ldavis_el3913106031220243521416100\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "\n",
       "var ldavis_el3913106031220243521416100_data = {\"mdsDat\": {\"Freq\": [26.46442015330101, 19.05714152004951, 18.924456089542666, 18.310662495011716, 17.24331974209511], \"cluster\": [1, 1, 1, 1, 1], \"topics\": [1, 2, 3, 4, 5], \"x\": [0.021158830425799018, 0.03887912063153517, 0.08715168165667182, 0.07387930513147947, -0.22106893784548545], \"y\": [0.078425511146775, -0.05460942430326781, -0.14574828551511806, 0.13602862566482438, -0.014096426993213555]}, \"tinfo\": {\"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\"], \"Freq\": [780.0, 325.0, 229.0, 199.0, 498.0, 146.0, 365.0, 202.0, 673.0, 273.0, 246.0, 140.0, 150.0, 143.0, 297.0, 125.0, 207.0, 281.0, 175.0, 126.0, 116.0, 180.0, 362.0, 137.0, 143.0, 480.0, 179.0, 167.0, 169.0, 98.0, 90.96125743252793, 129.17561993732497, 90.55989643851998, 72.3936099958087, 60.86253166733369, 58.279807830149295, 46.2959652662841, 45.79080830239397, 47.45889543272677, 43.907082577479514, 38.29900879159568, 37.018041923014614, 33.49483777571003, 42.27347670908464, 33.35971389648204, 33.19138321078468, 33.81390443886333, 33.31291965036806, 32.373590770168526, 32.88660049890302, 31.301729286537892, 198.37844612151702, 31.700617047620305, 30.8094219415494, 30.90529024007554, 30.270813021533765, 31.387311451364692, 49.229994051165654, 29.8037858924731, 29.272187761586544, 53.36152011894765, 120.06271273100006, 35.15010892635828, 109.14090917269608, 79.28442412337056, 71.76954557096222, 52.63767937112039, 76.76869704060213, 137.6205324679116, 170.00746933746672, 147.50036133871868, 82.49817639916469, 297.3355501788697, 79.2892201381885, 132.94332474802047, 91.0389126885498, 188.4800844897744, 223.42551546073406, 128.3086122750456, 85.51941693657785, 96.3607482862421, 116.51840993339404, 188.5211283864886, 245.27534653934822, 137.40160287285565, 173.83901277484506, 259.28729956998376, 184.57584054512813, 119.16239666019027, 159.291417720949, 136.77185995961403, 185.51386324313918, 241.94446056641948, 297.61802472443975, 157.94528867776364, 136.6041673591339, 212.45452993776684, 158.83256584110444, 205.41477058678183, 200.31990498563636, 172.22565406736334, 181.13994118427, 151.3684400192965, 151.3235416908463, 163.82178585742236, 158.05444749504156, 145.64900298456828, 139.59746015120638, 125.0016591167586, 64.00730851172607, 48.21095227400376, 43.19407288023505, 41.59581317625465, 36.47095597184488, 42.90373353761158, 35.38935204915811, 31.28651084034326, 30.893981527629645, 28.959408674905937, 58.8538667384124, 27.188509942596603, 34.09955687424906, 25.202575842626878, 28.43863510969839, 25.696179590946805, 24.70743194792502, 24.217605401721848, 24.94671753840561, 24.582536762935547, 22.700356079410472, 23.021739230963142, 24.55831259435443, 21.34157818531612, 20.919176729337156, 20.772879785272902, 19.04275513538828, 21.37247459195458, 22.3418689068342, 64.50385200737587, 32.937056657255255, 46.456292596709915, 51.431875296231404, 35.44529173717354, 92.30229958061528, 34.425967416098736, 49.63553905422304, 40.28375091628639, 69.69338027663578, 73.30144230782051, 63.577474281374236, 114.09245866438205, 49.2590244177474, 275.2521950143292, 322.2083145019721, 143.05287752826038, 118.54534079709673, 163.77226161290037, 149.81564238331922, 165.38316645792662, 71.95499393251623, 153.63233125229485, 234.76234502106135, 96.68430949992191, 85.76362229044679, 166.67121903268125, 129.8104240520981, 96.07686432295506, 96.62503767817401, 92.04813232553818, 174.74943353033507, 139.90872215700426, 215.12784584791842, 158.23227523552185, 117.19869687969909, 99.61761327314353, 109.75459428082952, 137.12016891340994, 118.75493868413055, 96.32177823221537, 117.77527605980174, 102.53959264149672, 100.74144608993096, 95.14855032130356, 53.82051048495146, 52.83627529485417, 44.144123902335636, 41.845113197245816, 36.7583066228238, 35.41754184213325, 32.29347392855028, 32.29850866021466, 29.696457468517664, 28.683796990437333, 28.70141529727934, 25.1146570532934, 26.54541640807606, 25.193638751223354, 23.47701232478314, 30.691597150191605, 26.69830458495425, 23.14798244748382, 22.185821338293792, 22.813806986801012, 21.99969643464332, 32.63442734437629, 21.546421679542263, 105.65994851485218, 21.304388408847284, 22.942847491316734, 19.45363532675279, 21.91045302730582, 20.55663340370073, 40.7779218893516, 53.9835571218848, 43.87507173095151, 39.38363556260636, 37.94738673167162, 52.29480343299875, 129.9864187558589, 25.921016511434168, 112.4979284373751, 89.18109268124138, 137.7120720540161, 141.3454547726794, 120.2170561829712, 187.01714866810784, 61.40845310814261, 44.09718693996179, 124.29197087199685, 198.73887245239078, 235.37068801624903, 178.44717279001657, 44.19546625131732, 257.1421036413301, 119.25804433689244, 94.38273970831422, 152.99721950060464, 84.5894385890155, 228.01415256114336, 109.21917642014282, 108.55011426884937, 126.4583691294253, 149.637228521738, 207.66469405060772, 113.69244119500678, 90.43176990055872, 203.23176762582656, 157.7427690032251, 132.6037350036652, 159.90253224821504, 137.06504138028518, 167.2580440289117, 129.02196782604582, 195.8675995995913, 140.01531508036285, 157.30941590292397, 151.72857273324405, 138.09197459590794, 135.75192465018472, 51.623096319982714, 49.211518895855086, 44.32238614012668, 42.759772024577906, 45.221627261104864, 38.679165362290036, 38.01400790671958, 40.615201615947115, 33.819848256659924, 32.510234788120464, 30.864875350590726, 27.791276181717496, 27.11765111003578, 27.625915423319206, 42.82693108428797, 26.545802129019204, 27.662506095834726, 25.454435290624577, 25.420373303439163, 24.098006463653658, 23.278201905751686, 25.00267502954261, 22.778475846313984, 24.00196296254973, 37.53957069063292, 31.63167897447117, 22.675802485410376, 21.5483347972487, 22.026690635692944, 26.733999919392918, 122.47083969692973, 79.95711678905079, 83.03643441897302, 62.79404154824221, 135.85657326684253, 86.8555746668128, 210.29526665381925, 36.457456591933976, 34.15582013082497, 125.54586007316908, 56.09747485365623, 34.17541980477268, 109.54083130974198, 160.78691446162355, 55.31863551486772, 191.4342554321739, 97.85010497278631, 66.73036464790351, 58.504176424670234, 63.86181755111615, 486.4391578554619, 218.8446588828154, 100.33759394796145, 64.81079924270001, 233.96859654533986, 118.77463967855402, 208.2904390506979, 211.1584769104597, 123.235543237335, 139.2783121448992, 92.29851184752623, 102.96568108920965, 115.23051936259054, 139.4229441359672, 125.76761817610995, 96.01789178079034, 99.39000912982854, 105.52326362676628, 128.00069277710176, 114.12943300096178, 113.5730663152749, 101.34182102682233, 107.35517938635307, 95.28321170693565, 52.89756557265337, 71.58557214815202, 51.40532663810799, 38.44414564203824, 144.00081419198247, 96.94471915483098, 37.37744117194419, 32.813730454618835, 31.55205343014167, 114.3250281388388, 26.946010217307766, 25.919901953034483, 27.716493592382495, 24.326451349324444, 29.34846207257924, 23.58513660060446, 23.103965119931487, 22.61166865487517, 21.958792772452433, 21.973937837731423, 23.44404931123756, 22.142141040774924, 21.803869266396994, 21.19504479337726, 21.66933721446937, 68.90940231976538, 21.48305459575933, 21.146609141541667, 21.36898362644862, 20.22146119364051, 62.01096979153145, 37.69884950827354, 29.30601335725787, 187.89555388436443, 55.779538978445544, 131.04361135380765, 41.40875564605925, 132.81506679696204, 98.54204915281088, 43.07909532348846, 36.50723865616668, 51.496183014219845, 31.936654287532704, 249.0818760555708, 525.504499900771, 95.13861475496198, 135.10291144135365, 65.77329527419258, 87.12253419426465, 108.0764754412442, 113.45483283439835, 44.95263854628084, 78.5460687759789, 58.233288555113184, 52.887597393614705, 87.52773946010385, 117.16029938850723, 122.1205550161489, 67.22601920575717, 87.09716008629673, 117.68273590558212, 87.09526713024025, 87.4826846951447, 75.85791592544597, 116.06302703774693, 182.8833449900166, 141.62205204860356, 108.89964457963337, 94.48323692025056, 81.54045933012301, 94.76064961398643, 91.66331374977977, 80.5652186615121], \"Term\": [\"women\", \"trump\", \"jenner\", \"clinton\", \"best\", \"state\", \"summer\", \"red\", \"can\", \"littl\", \"movi\", \"hillari\", \"presid\", \"hadid\", \"beauti\", \"abort\", \"pretti\", \"kardashian\", \"donald\", \"kyli\", \"obama\", \"job\", \"2016\", \"harri\", \"product\", \"star\", \"trend\", \"fall\", \"top\", \"survey\", \"jojo\", \"carpet\", \"dream\", \"don\", \"gilmor\", \"anyon\", \"dark\", \"blogger\", \"competit\", \"financi\", \"golden\", \"achiev\", \"green\", \"fletcher\", \"truth\", \"cheat\", \"fox\", \"nomin\", \"spear\", \"truli\", \"polish\", \"red\", \"dr.\", \"allen\", \"sheldon\", \"annual\", \"bernadett\", \"mtv\", \"winner\", \"britney\", \"perri\", \"selena\", \"realiz\", \"gomez\", \"kati\", \"gala\", \"along\", \"bang\", \"award\", \"taylor\", \"swift\", \"blake\", \"girl\", \"west\", \"music\", \"engag\", \"kardashian\", \"live\", \"kim\", \"met\", \"perform\", \"moment\", \"celebr\", \"first\", \"big\", \"night\", \"time\", \"2016\", \"relationship\", \"instagram\", \"video\", \"us\", \"just\", \"new\", \"love\", \"photo\", \"look\", \"see\", \"get\", \"one\", \"year\", \"like\", \"hair\", \"come\", \"show\", \"will\", \"star\", \"day\", \"abort\", \"sometim\", \"lemonad\", \"clean\", \"network\", \"5\", \"phone\", \"judg\", \"agre\", \"gain\", \"tough\", \"hour\", \"bridesmaid\", \"pass\", \"7\", \"rowl\", \"sun\", \"appli\", \"healthi\", \"anim\", \"hire\", \"carpool\", \"4\", \"bright\", \"blood\", \"karaok\", \"determin\", \"unicorn\", \"anxieti\", \"j.k.\", \"doctor\", \"breakup\", \"certain\", \"bride\", \"cancer\", \"health\", \"obvious\", \"advic\", \"minut\", \"http\", \"bad\", \"noth\", \"expert\", \"vote\", \"can\", \"get\", \"sex\", \"life\", \"even\", \"thing\", \"say\", \"sure\", \"way\", \"one\", \"stori\", \"real\", \"know\", \"week\", \"everi\", \"date\", \"actual\", \"just\", \"now\", \"new\", \"women\", \"hair\", \"use\", \"season\", \"like\", \"best\", \"help\", \"year\", \"work\", \"look\", \"go\", \"nine\", \"olymp\", \"especi\", \"earn\", \"epic\", \"extra\", \"activ\", \"altern\", \"orang\", \"coffe\", \"appl\", \"gym\", \"recip\", \"florida\", \"la\", \"grey\", \"globe\", \"bare\", \"isn\", \"andrew\", \"newli\", \"sell\", \"bottom\", \"wonder\", \"scent\", \"ingredi\", \"a-list\", \"hailey\", \"feet\", \"jenna\", \"tatum\", \"amount\", \"sale\", \"generat\", \"boot\", \"product\", \"dewan\", \"shop\", \"buy\", \"fall\", \"trend\", \"skin\", \"movi\", \"presidenti\", \"millenni\", \"top\", \"beauti\", \"summer\", \"wear\", \"stream\", \"best\", \"wed\", \"tv\", \"good\", \"netflix\", \"can\", \"$\", \"favorit\", \"dress\", \"work\", \"show\", \"makeup\", \"idea\", \"just\", \"know\", \"2016\", \"make\", \"day\", \"look\", \"way\", \"new\", \"now\", \"get\", \"one\", \"will\", \"like\", \"vagina\", \"search\", \"liar\", \"gun\", \"within\", \"ultim\", \"rather\", \"dog\", \"count\", \"bathroom\", \"gwen\", \"signific\", \"locat\", \"camera\", \"crazi\", \"journey\", \"invest\", \"simon\", \"surviv\", \"attempt\", \"stefani\", \"primari\", \"rob\", \"tend\", \"elimin\", \"luna\", \"wall\", \"cold\", \"prevent\", \"voter\", \"kyli\", \"bella\", \"snapchat\", \"potter\", \"hadid\", \"gigi\", \"jenner\", \"tear\", \"glow\", \"harri\", \"princ\", \"sarah\", \"kendal\", \"pretti\", \"mayb\", \"littl\", \"citi\", \"bachelor\", \"heard\", \"kate\", \"new\", \"star\", \"york\", \"disney\", \"look\", \"final\", \"show\", \"like\", \"last\", \"week\", \"pictur\", \"back\", \"season\", \"time\", \"make\", \"reveal\", \"night\", \"see\", \"just\", \"will\", \"one\", \"us\", \"get\", \"year\", \"credit\", \"student\", \"access\", \"abc\", \"state\", \"survey\", \"south\", \"howev\", \"nice\", \"obama\", \"18\", \"fine\", \"impress\", \"googl\", \"barack\", \"spice\", \"stretch\", \"tax\", \"employ\", \"paid\", \"paper\", \"breakfast\", \"bath\", \"sport\", \"bold\", \"food\", \"san\", \"toni\", \"area\", \"ugli\", \"republican\", \"employe\", \"rate\", \"clinton\", \"unit\", \"hillari\", \"card\", \"presid\", \"countri\", \"dinner\", \"allow\", \"across\", \"stress\", \"trump\", \"women\", \"elect\", \"donald\", \"assault\", \"percent\", \"sexual\", \"men\", \"michell\", \"tattoo\", \"gender\", \"law\", \"nation\", \"job\", \"report\", \"pay\", \"studi\", \"accord\", \"plan\", \"hous\", \"femal\", \"right\", \"new\", \"one\", \"make\", \"peopl\", \"recent\", \"show\", \"will\", \"say\"], \"Total\": [780.0, 325.0, 229.0, 199.0, 498.0, 146.0, 365.0, 202.0, 673.0, 273.0, 246.0, 140.0, 150.0, 143.0, 297.0, 125.0, 207.0, 281.0, 175.0, 126.0, 116.0, 180.0, 362.0, 137.0, 143.0, 480.0, 179.0, 167.0, 169.0, 98.0, 91.63880038714987, 130.21348729495858, 91.41114985855663, 73.11789323429633, 61.48760788029148, 58.92423006056974, 46.934497253141956, 46.432828529339154, 48.17446874543932, 44.60544065346494, 38.935623347497376, 37.69693109951973, 34.12111361172904, 43.0715865851728, 33.99324435875124, 33.82507937578827, 34.460111428731174, 33.952390216183396, 32.99730521455973, 33.5248301544545, 31.935435126601114, 202.42753630978052, 32.35116728259324, 31.44246219428331, 31.541341690932434, 30.899460001265403, 32.040805817565854, 50.26000448806142, 30.42978746651612, 29.89723088358157, 54.65224200567196, 124.17396540566152, 35.9162688217202, 113.30429370754959, 82.56917237464086, 75.27131950281705, 55.17641803409041, 82.33852298248634, 155.58391922133768, 203.30454878566906, 176.6986770237265, 94.14362256908208, 405.71501436183183, 90.42905888028585, 166.0835753549356, 113.78060123881582, 281.12899299329814, 349.7248945330127, 177.6742343390724, 107.23846880105253, 126.96912638707121, 165.4275774054919, 320.5046626630145, 501.2818888085367, 218.43148049752952, 310.68990963327417, 599.3040321996684, 362.4573300692839, 184.0220022966888, 302.0984071469011, 235.187888681821, 416.1065722869683, 818.6599283111872, 1377.935973017428, 370.2733438346817, 272.06367302816307, 727.4741751800747, 402.9184527793275, 848.5945165388202, 842.0059411038202, 558.7868673521077, 743.9211974479514, 404.8476913282833, 412.7091029340547, 690.6768386680457, 586.5002937408788, 480.17636531565813, 417.41639573468245, 125.6441922475397, 64.65571675831451, 48.877161272153224, 43.84482270860485, 42.26038096361738, 37.127823307543196, 43.67958277204725, 36.12594484030396, 31.941059112979627, 31.546231281450304, 29.60448082665336, 60.17798159041133, 27.836972252362568, 34.92667753086612, 25.848376914349984, 29.173463647040602, 26.367804020972834, 25.35842771037412, 24.85947484558506, 25.617720070557915, 25.275450764770632, 23.34172421224896, 23.676106475092727, 25.260812876667945, 21.987275540557164, 21.56136899208849, 21.42398809485028, 19.682114652777276, 22.09399667866294, 23.096304708559252, 66.86226780255294, 34.06521157091532, 48.74314955098475, 54.12910324461801, 37.10341519079552, 104.66838483264748, 36.572707878915764, 55.76145532712247, 44.28406152274649, 86.48119784023572, 95.8956838709018, 80.65270160620906, 181.4777480385685, 63.046408497361284, 673.4497957561975, 848.5945165388202, 301.6497476645429, 231.14397493692823, 396.964302175724, 357.7050915832711, 420.51188036714836, 116.38454189113128, 400.8513058598595, 842.0059411038202, 193.32279765136576, 159.85626594433634, 505.9063557758353, 398.5132617942281, 224.50805481111732, 228.3756177306885, 208.62690941011533, 818.6599283111872, 510.69307350315404, 1377.935973017428, 780.5793453461221, 404.8476913282833, 281.3940002035828, 374.6928062858452, 743.9211974479514, 498.88993163373345, 266.4310539017446, 558.7868673521077, 384.05156406040624, 727.4741751800747, 406.00136162939475, 54.46988034632627, 53.4888877840644, 44.81429055457646, 42.510246504642176, 37.405586476916085, 36.06239777092644, 32.94698313868655, 32.98415282732046, 30.333162840917247, 29.31266589692875, 29.36033935383589, 25.738358383930688, 27.241542475685876, 25.8596515320905, 24.098517226788637, 31.517421437561936, 27.427052461082255, 23.795855539989, 22.816185521360943, 23.46320841663576, 22.640399571228663, 33.600975269187245, 22.191153603065906, 108.87402815755142, 21.957570497718393, 23.66535953669597, 20.09010328304044, 22.62794823375218, 21.25311748146341, 42.180110218410796, 56.05438502190786, 45.55766894980735, 41.04155562129081, 39.63092420511476, 55.17298110866334, 143.39829646493018, 26.84634814466917, 126.48044346797684, 102.01781630304795, 167.53249135517166, 179.26378172219805, 149.71538359670296, 246.6045116227338, 71.76898453583318, 49.05228116088898, 169.8472644564226, 297.5889456080297, 365.6846504947998, 304.98508641353396, 50.51965770149891, 498.88993163373345, 215.19854698056602, 153.60558800747427, 311.4493557418704, 132.62477729594798, 673.4497957561975, 209.50397843720617, 207.7819204779703, 283.6224705954235, 384.05156406040624, 690.6768386680457, 255.48568487799955, 171.33711025268394, 818.6599283111872, 505.9063557758353, 362.4573300692839, 549.3361163021524, 417.41639573468245, 727.4741751800747, 400.8513058598595, 1377.935973017428, 510.69307350315404, 848.5945165388202, 842.0059411038202, 586.5002937408788, 743.9211974479514, 52.25511149930905, 49.868980597676035, 44.9519489461081, 43.43241409239478, 45.96281863927386, 39.31951157376532, 38.66883534139022, 41.364380328406405, 34.4743811898526, 33.157639353885266, 31.490497364856505, 28.428731696167137, 27.744824620395015, 28.27922804575336, 43.84444173800062, 27.177840045903697, 28.328440537950126, 26.071863001193048, 26.06321878124947, 24.729217567680966, 23.904415980912297, 25.678264260568564, 23.402601590215017, 24.663798548475526, 38.58322440910943, 32.526726821327216, 23.321138400419084, 22.175900327252766, 22.673026476726395, 27.52659651296448, 126.85011354014459, 82.57727654936508, 85.89782224005165, 65.05266051509709, 143.61156587883295, 92.27550594606566, 229.96114580869076, 37.89194586633749, 35.46833894145436, 137.9037883155162, 59.86579093201158, 35.60484143786842, 127.75848840037874, 207.0492376204725, 62.827617990526385, 273.5028766606128, 131.08387711972003, 85.76592032323717, 72.85362158470187, 82.78750552068269, 1377.935973017428, 480.17636531565813, 165.40947235659178, 87.61385931134399, 727.4741751800747, 261.46468545268425, 690.6768386680457, 743.9211974479514, 311.7915395327746, 398.5132617942281, 204.53405000878985, 281.28469904236084, 374.6928062858452, 599.3040321996684, 549.3361163021524, 279.338335362185, 310.68990963327417, 402.9184527793275, 818.6599283111872, 586.5002937408788, 842.0059411038202, 416.1065722869683, 848.5945165388202, 558.7868673521077, 53.5794014410994, 72.54790696048198, 52.18789526280835, 39.09702669342305, 146.55963484079464, 98.79281268039455, 38.09623140003956, 33.446657847221246, 32.22767531879374, 116.82382073504097, 27.59230309644355, 26.565877253910028, 28.410171984532123, 24.948525526958193, 30.09928716367642, 24.235217662744827, 23.74514432405683, 23.24017904236978, 22.581698830018922, 22.599548662559105, 24.113760817734992, 22.77850803710552, 22.444751417548883, 21.819671880587848, 22.31001823365711, 70.99180097305835, 22.13312430794087, 21.80074423662463, 22.03117553466975, 20.855188917930757, 64.50998060551534, 39.03473883692075, 30.28162632944651, 199.33445627310545, 58.16516002383483, 140.12121202605599, 43.92103854111215, 150.96800383761965, 111.02475291536338, 46.18021793397509, 38.82192648793233, 56.31212528288704, 33.71841613673886, 325.824196756962, 780.5793453461221, 115.87687402384795, 175.95845163388665, 77.87250948209866, 107.98156885980453, 139.6471738108904, 148.21740517081253, 50.03648205378733, 99.04624912640259, 68.62196843451017, 61.61343191183849, 117.91093334286872, 180.52884906350982, 229.02000436286116, 91.58080097143056, 146.51995030405206, 248.8124810567578, 160.67583132995028, 166.10300031860663, 125.56245376338936, 346.5551978396979, 1377.935973017428, 842.0059411038202, 549.3361163021524, 347.33648872229804, 204.19859810522115, 690.6768386680457, 586.5002937408788, 420.51188036714836], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 1.3219, 1.3214, 1.32, 1.3194, 1.3192, 1.3184, 1.3157, 1.3154, 1.3144, 1.3136, 1.3129, 1.3112, 1.3108, 1.3107, 1.3106, 1.3105, 1.3104, 1.3104, 1.3103, 1.3101, 1.3093, 1.3092, 1.3091, 1.309, 1.309, 1.3088, 1.3088, 1.3087, 1.3086, 1.3082, 1.3055, 1.2957, 1.3078, 1.2919, 1.2888, 1.2817, 1.2823, 1.2593, 1.2067, 1.1505, 1.1488, 1.1973, 1.0186, 1.1979, 1.1068, 1.1064, 0.9295, 0.8813, 1.0039, 1.1031, 1.0535, 0.9789, 0.7987, 0.6146, 0.8658, 0.7487, 0.4915, 0.6545, 0.8948, 0.6894, 0.7873, 0.5216, 0.1104, -0.2032, 0.4774, 0.6404, 0.0985, 0.3985, -0.0892, -0.1065, 0.1524, -0.0833, 0.3456, 0.326, -0.1095, 0.0181, 0.1364, 0.234, 1.6526, 1.6476, 1.644, 1.6428, 1.6419, 1.6399, 1.6398, 1.6371, 1.637, 1.6368, 1.6357, 1.6355, 1.6342, 1.6338, 1.6324, 1.6322, 1.6319, 1.6317, 1.6316, 1.6312, 1.6299, 1.6299, 1.6297, 1.6295, 1.6279, 1.6275, 1.6269, 1.6247, 1.6245, 1.6245, 1.6218, 1.624, 1.6097, 1.6066, 1.612, 1.532, 1.5972, 1.5414, 1.5631, 1.4419, 1.389, 1.4198, 1.1936, 1.4109, 0.763, 0.6893, 0.9117, 0.99, 0.7724, 0.7874, 0.7245, 1.1769, 0.6987, 0.3805, 0.9648, 1.035, 0.5474, 0.5361, 0.809, 0.7976, 0.8395, 0.1134, 0.3629, -0.1994, 0.0618, 0.4181, 0.6193, 0.4299, -0.0333, 0.2224, 0.6403, 0.1007, 0.3372, -0.3193, 0.2068, 1.6527, 1.6524, 1.6496, 1.6489, 1.6473, 1.6467, 1.6447, 1.6437, 1.6435, 1.643, 1.642, 1.6402, 1.6388, 1.6386, 1.6386, 1.6382, 1.6378, 1.6371, 1.6367, 1.6366, 1.636, 1.6355, 1.6352, 1.6347, 1.6345, 1.6337, 1.6325, 1.6325, 1.6314, 1.6309, 1.6271, 1.6271, 1.6235, 1.6213, 1.6111, 1.5665, 1.6296, 1.5476, 1.5302, 1.4687, 1.4271, 1.4453, 1.3881, 1.5088, 1.5582, 1.3524, 1.261, 1.2241, 1.1287, 1.531, 1.002, 1.0744, 1.1777, 0.9539, 1.215, 0.5817, 1.0133, 1.0154, 0.857, 0.7222, 0.463, 0.855, 1.0257, 0.2714, 0.4993, 0.6592, 0.4306, 0.5511, 0.1947, 0.5311, -0.2862, 0.3707, -0.0207, -0.049, 0.2185, -0.0364, 1.6855, 1.6844, 1.6836, 1.6821, 1.6814, 1.6813, 1.6806, 1.6794, 1.6785, 1.678, 1.6776, 1.675, 1.6748, 1.6743, 1.6742, 1.6742, 1.6739, 1.6737, 1.6727, 1.6718, 1.6711, 1.671, 1.6707, 1.6705, 1.6703, 1.6698, 1.6696, 1.669, 1.6688, 1.6685, 1.6626, 1.6654, 1.6638, 1.6623, 1.6422, 1.6372, 1.6083, 1.6591, 1.66, 1.6038, 1.6327, 1.6567, 1.5438, 1.4448, 1.5704, 1.3409, 1.4053, 1.4467, 1.4783, 1.4381, 0.6565, 0.9119, 1.1978, 1.3962, 0.5633, 0.9086, 0.4989, 0.4384, 0.7694, 0.6464, 0.902, 0.6927, 0.5185, 0.2394, 0.2234, 0.6298, 0.5579, 0.3579, -0.1579, 0.0608, -0.3057, 0.2852, -0.3698, -0.0712, 1.7449, 1.7444, 1.7426, 1.7409, 1.7401, 1.7389, 1.7387, 1.7386, 1.7366, 1.7361, 1.734, 1.7331, 1.733, 1.7325, 1.7325, 1.7306, 1.7304, 1.7303, 1.7298, 1.7297, 1.7296, 1.7294, 1.7288, 1.7287, 1.7286, 1.728, 1.7279, 1.7273, 1.7272, 1.7269, 1.7182, 1.7229, 1.725, 1.6986, 1.7159, 1.6908, 1.6988, 1.6296, 1.6385, 1.6882, 1.6963, 1.6683, 1.7035, 1.4892, 1.3621, 1.5606, 1.4935, 1.5889, 1.5431, 1.5015, 1.4905, 1.6506, 1.5258, 1.5936, 1.605, 1.4598, 1.3254, 1.1289, 1.4486, 1.2376, 1.009, 1.1454, 1.1166, 1.2538, 0.6638, -0.2617, -0.0249, 0.1395, 0.4559, 0.8398, -0.2286, -0.0983, 0.1053], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -6.2051, -5.8544, -6.2095, -6.4334, -6.6069, -6.6503, -6.8805, -6.8915, -6.8557, -6.9335, -7.0701, -7.1041, -7.2042, -6.9714, -7.2082, -7.2133, -7.1947, -7.2096, -7.2382, -7.2225, -7.2719, -5.4254, -7.2592, -7.2877, -7.2846, -7.3054, -7.2692, -6.8191, -7.3209, -7.3389, -6.7385, -5.9275, -7.1559, -6.0229, -6.3425, -6.4421, -6.7521, -6.3748, -5.7911, -5.5797, -5.7217, -6.3028, -5.0207, -6.3425, -5.8256, -6.2043, -5.4766, -5.3065, -5.8611, -6.2668, -6.1475, -5.9575, -5.4763, -5.2132, -5.7926, -5.5574, -5.1576, -5.4975, -5.9351, -5.6448, -5.7972, -5.4924, -5.2268, -5.0197, -5.6533, -5.7985, -5.3568, -5.6477, -5.3905, -5.4156, -5.5667, -5.5163, -5.6958, -5.6961, -5.6168, -5.6526, -5.7344, -5.7768, -5.5589, -6.2282, -6.5116, -6.6215, -6.6592, -6.7907, -6.6282, -6.8208, -6.944, -6.9566, -7.0213, -6.3121, -7.0844, -6.8579, -7.1602, -7.0394, -7.1409, -7.1801, -7.2001, -7.1705, -7.1852, -7.2648, -7.2508, -7.1861, -7.3265, -7.3465, -7.3535, -7.4405, -7.3251, -7.2807, -6.2205, -6.8926, -6.5487, -6.4469, -6.8192, -5.8621, -6.8484, -6.4825, -6.6912, -6.1431, -6.0926, -6.2349, -5.6502, -6.4901, -4.7695, -4.612, -5.424, -5.6119, -5.2887, -5.3778, -5.2789, -6.1112, -5.3526, -4.9286, -5.8157, -5.9356, -5.2712, -5.5211, -5.822, -5.8164, -5.8649, -5.2238, -5.4462, -5.016, -5.3231, -5.6233, -5.7859, -5.6889, -5.4663, -5.6101, -5.8195, -5.6184, -5.7569, -5.7746, -5.8318, -6.3946, -6.413, -6.5927, -6.6462, -6.7758, -6.813, -6.9053, -6.9052, -6.9892, -7.0239, -7.0233, -7.1568, -7.1014, -7.1536, -7.2242, -6.9562, -7.0956, -7.2383, -7.2808, -7.2528, -7.2892, -6.8948, -7.31, -5.72, -7.3213, -7.2472, -7.4122, -7.2932, -7.357, -6.6721, -6.3915, -6.5989, -6.7069, -6.744, -6.4233, -5.5128, -7.1252, -5.6573, -5.8895, -5.455, -5.429, -5.5909, -5.149, -6.2627, -6.5938, -5.5576, -5.0882, -4.919, -5.1959, -6.5916, -4.8306, -5.5989, -5.8329, -5.3498, -5.9424, -4.9508, -5.6869, -5.693, -5.5403, -5.372, -5.0443, -5.6467, -5.8756, -5.0659, -5.3192, -5.4928, -5.3056, -5.4598, -5.2607, -5.5202, -5.1028, -5.4385, -5.322, -5.3581, -5.4523, -5.4694, -6.4033, -6.4511, -6.5557, -6.5916, -6.5357, -6.6919, -6.7093, -6.6431, -6.8262, -6.8657, -6.9176, -7.0225, -7.0471, -7.0285, -6.5901, -7.0684, -7.0272, -7.1103, -7.1117, -7.1651, -7.1997, -7.1283, -7.2214, -7.1691, -6.7218, -6.8931, -7.2259, -7.2769, -7.255, -7.0613, -5.5394, -5.9657, -5.928, -6.2074, -5.4356, -5.883, -4.9987, -6.7511, -6.8163, -5.5146, -6.3201, -6.8157, -5.6509, -5.2672, -6.3341, -5.0927, -5.7638, -6.1466, -6.2781, -6.1905, -4.1601, -4.9589, -5.7387, -6.1758, -4.892, -5.57, -5.0083, -4.9946, -5.5331, -5.4108, -5.8222, -5.7128, -5.6003, -5.4097, -5.5128, -5.7827, -5.7482, -5.6883, -5.4952, -5.6099, -5.6148, -5.7287, -5.6711, -5.7904, -6.3188, -6.0163, -6.3474, -6.638, -5.3174, -5.713, -6.6661, -6.7963, -6.8355, -5.5481, -6.9933, -7.0322, -6.9652, -7.0956, -6.9079, -7.1266, -7.1472, -7.1687, -7.198, -7.1973, -7.1326, -7.1897, -7.2051, -7.2334, -7.2113, -6.0544, -7.2199, -7.2357, -7.2252, -7.2804, -6.1599, -6.6575, -6.9094, -5.0513, -6.2658, -5.4116, -6.5637, -5.3982, -5.6967, -6.5241, -6.6897, -6.3457, -6.8234, -4.7694, -4.0228, -5.7318, -5.3811, -6.101, -5.8199, -5.6043, -5.5558, -6.4816, -5.9235, -6.2227, -6.319, -5.8152, -5.5236, -5.4822, -6.0791, -5.8202, -5.5192, -5.8202, -5.8157, -5.9583, -5.533, -5.0783, -5.334, -5.5968, -5.7388, -5.8861, -5.7358, -5.7691, -5.8981]}, \"token.table\": {\"Topic\": [1, 2, 3, 4, 5, 5, 1, 3, 5, 2, 2, 2, 3, 5, 2, 5, 1, 2, 3, 4, 5, 1, 1, 3, 5, 3, 1, 2, 3, 4, 5, 2, 4, 5, 2, 1, 4, 5, 1, 4, 3, 1, 3, 3, 2, 1, 2, 1, 3, 2, 5, 1, 2, 5, 4, 1, 2, 3, 5, 1, 2, 3, 4, 1, 2, 3, 4, 5, 2, 3, 4, 5, 1, 4, 5, 3, 5, 4, 1, 2, 3, 4, 5, 1, 3, 4, 1, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 3, 1, 2, 5, 3, 4, 5, 3, 5, 2, 5, 1, 2, 5, 2, 2, 1, 1, 2, 3, 4, 4, 1, 2, 3, 4, 5, 1, 2, 1, 3, 5, 1, 2, 1, 2, 3, 4, 5, 1, 2, 1, 1, 2, 3, 4, 5, 2, 1, 4, 5, 3, 4, 1, 2, 3, 4, 5, 1, 4, 1, 2, 3, 4, 5, 4, 5, 1, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 2, 3, 3, 5, 1, 4, 5, 2, 5, 4, 1, 1, 3, 4, 5, 1, 1, 1, 2, 3, 4, 5, 3, 1, 2, 3, 5, 4, 5, 4, 5, 1, 2, 3, 4, 5, 3, 3, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 3, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 3, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 5, 1, 2, 3, 4, 5, 1, 3, 2, 5, 1, 2, 1, 3, 4, 1, 5, 3, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 1, 2, 3, 4, 5, 3, 2, 4, 1, 2, 3, 4, 5, 1, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 5, 1, 3, 4, 4, 3, 1, 2, 3, 4, 5, 3, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 2, 4, 5, 2, 3, 4, 1, 2, 3, 4, 5, 1, 4, 5, 2, 2, 3, 1, 2, 3, 4, 5, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 5, 3, 1, 2, 3, 4, 5, 4, 3, 2, 1, 3, 1, 2, 3, 4, 1, 2, 5, 1, 4, 2, 1, 2, 3, 4, 5, 2, 1, 2, 3, 4, 5, 1, 3, 4, 5, 1, 2, 3, 1, 3, 4, 1, 2, 4, 1, 2, 3, 4, 5, 3, 4, 3, 1, 2, 3, 4, 5, 1, 2, 4, 5, 2, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 2, 4, 5, 1, 2, 3, 4, 5, 1, 3, 4, 1, 4, 5, 1, 3, 2, 4, 1, 2, 3, 4, 1, 2, 3, 4, 5, 1, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 2, 1, 2, 3, 4, 5, 3, 5, 1, 2, 3, 4, 5, 3, 1, 1, 2, 1, 2, 3, 4, 5, 1, 4, 5, 2, 3, 3, 1, 2, 3, 4, 5, 3, 5, 5, 2, 1, 2, 3, 5, 1, 2, 3, 4, 5, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 2, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 3, 4, 1, 2, 4, 5, 1, 3, 4, 1, 2, 3, 4, 5, 4, 4, 1, 2, 4, 1, 2, 3, 4, 5, 4, 5, 4, 1, 2, 3, 4, 5, 1, 1, 2, 3, 4, 5, 3, 1, 2, 3, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 4, 2, 1, 3, 5, 1, 2, 4, 1, 2, 3, 4, 5, 3, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 3, 1, 2, 3, 4, 5, 1, 2, 4, 5, 1, 3, 4, 5, 1, 2, 3, 4, 5, 4, 4, 1, 2, 3, 4, 1, 4, 2, 5, 1, 5, 5, 1, 2, 3, 4, 5, 1, 3, 4, 5, 4, 1, 2, 3, 4, 5, 1, 2, 3, 5, 1, 5, 5, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 2, 1, 2, 3, 5, 1, 5, 4, 1, 2, 4, 5, 1, 3, 4, 5, 1, 3, 4, 5, 1, 2, 4, 5, 2, 4, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 5, 1, 2, 3, 4, 2, 1, 2, 3, 4, 5, 1, 1, 2, 3, 4, 5, 1, 1, 2, 3, 4, 5, 5, 4, 2, 1, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 4, 1, 2, 3, 4, 5, 2, 4, 5, 4, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 5, 1, 2, 3, 4, 5, 1, 2, 4, 1, 2, 3, 4, 5, 1, 4, 1, 2, 3, 4, 5, 1, 3, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 4, 5], \"Freq\": [0.06205132760233687, 0.1766076247143434, 0.520276516050363, 0.04295861141700245, 0.19570034089967783, 0.9785337565199516, 0.5104049074263091, 0.366939744257833, 0.12415254504964275, 0.9714435109588652, 0.9696232311223573, 0.9671787162048462, 0.9457392892568812, 0.9719409176041617, 0.9948728848025817, 0.9772381074801669, 0.08842000170795883, 0.2491836411769749, 0.09243909269468424, 0.10047727466813504, 0.4742527364335974, 0.981512258977267, 0.05327449434609928, 0.03551632956406619, 0.9056664038836878, 0.971257364150753, 0.0814851739311427, 0.4409785883332429, 0.27321499494559615, 0.10065815603258804, 0.10545140155794938, 0.8966767403518594, 0.07173413922814875, 0.035867069614074376, 0.9705376359108513, 0.9859278770361771, 0.051517278531288076, 0.9530696528288294, 0.960555285905915, 0.03624736927946849, 0.9701628587378697, 0.021950201207654823, 0.9658088531368123, 0.9802580956359175, 0.9758870005271135, 0.9708907533908823, 0.9504844372625684, 0.9843149403968503, 0.9877270031012495, 0.9858655388864079, 0.9531947111470733, 0.06420751088225043, 0.08989051523515061, 0.8475391436457057, 0.9705119029469823, 0.886981126909894, 0.00642739947036155, 0.0257095978814462, 0.0771287936443386, 0.13991571424610197, 0.04663857141536732, 0.02331928570768366, 0.7811960712074026, 0.28085423867333353, 0.1884211980972997, 0.08887792363080174, 0.3661770453589032, 0.07821257279510553, 0.7612438542935385, 0.10427998004021075, 0.05213999002010537, 0.07299598602814752, 0.9351637266602189, 0.06072491731559863, 0.9634779668469017, 0.9665548675629014, 0.9801846137978991, 0.995245760646504, 0.19826005256832374, 0.030243058866354467, 0.6687076349338377, 0.09408951647310279, 0.013441359496157542, 0.01210986898317233, 0.01210986898317233, 0.9687895186537864, 0.967516240899433, 0.222493967028968, 0.23852956825628102, 0.5151436894274305, 0.01603560122731301, 0.008017800613656504, 0.6271989719062014, 0.22432663958688956, 0.05951523091080743, 0.07782760965259433, 0.013734284056340177, 0.8710096102349242, 0.11684275259248983, 0.9906783940791876, 0.9550978683677266, 0.9861040797721351, 0.9424903087543132, 0.018124813629890636, 0.03624962725978127, 0.9913860447958192, 0.9658226941010642, 0.9687302229520045, 0.029355461301575896, 0.01847435002720886, 0.9421918513876519, 0.03694870005441772, 0.9699330715720518, 0.9896751985796608, 0.969989498790863, 0.04901104710129555, 0.058813256521554655, 0.8723966384030608, 0.00980220942025911, 0.9901260371994033, 0.12621579297467295, 0.4083452125651183, 0.33855530350853447, 0.028212941959044537, 0.09800285101562839, 0.02695169689522479, 0.9433093913328676, 0.02276813192984845, 0.0455362638596969, 0.9334934091237864, 0.990680786451792, 0.9853599413161761, 0.5896950092071473, 0.05616142944829974, 0.18408468541387138, 0.09672246182762734, 0.07488190593106633, 0.04103140684226866, 0.9437223573721791, 0.975607466678146, 0.007628703254532908, 0.04577221952719745, 0.03814351627266454, 0.747612918944225, 0.16783147159972397, 0.9807315286865318, 0.03010016487957045, 0.025083470732975375, 0.943138499559874, 0.9893334199615904, 0.992067951034367, 0.36587513802458516, 0.20353318936466988, 0.21080223184197952, 0.16961099113722491, 0.05088329734116747, 0.9756205148489466, 0.9862396024676947, 0.08106300409297824, 0.00900700045477536, 0.00900700045477536, 0.00900700045477536, 0.8916930450227607, 0.9807400504025866, 0.9891861158296749, 0.9800893307091002, 0.1882862996815521, 0.42473886207233846, 0.1357412858169329, 0.14887753928308772, 0.10509002772923838, 0.3353965043792544, 0.15571980560465382, 0.32820943642827033, 0.050309475656888154, 0.1293672231177124, 0.9802096559719339, 0.9684743660438141, 0.043308587301589735, 0.9311346269841793, 0.19403322868804262, 0.7418917567483982, 0.05706859667295371, 0.9721477020783637, 0.029912236987026577, 0.9911909636863054, 0.9847110852782068, 0.1932274334326557, 0.01136631961368563, 0.02273263922737126, 0.7672265739237799, 0.9891451433722398, 0.9955021913717002, 0.3067457942149518, 0.021154882359651846, 0.4442525295526888, 0.08814534316521604, 0.14103254906434565, 0.9879970937221816, 0.10355819572359494, 0.017259699287265822, 0.05177909786179747, 0.8198357161451266, 0.9848839899194187, 0.9742402538268892, 0.025618206494932575, 0.9734918468074378, 0.7997848403788861, 0.09667728839744777, 0.00878884439976798, 0.0878884439976798, 0.00878884439976798, 0.9891570614147065, 0.9818296676238847, 0.18389562890137442, 0.41313538547706036, 0.17130003788073234, 0.06297795510321041, 0.17130003788073234, 0.38751393607322765, 0.427601584632527, 0.16035059423719764, 0.00445418317325549, 0.01781673269302196, 0.08816507904098306, 0.6281761881670043, 0.2534746022428263, 0.027551587200307204, 0.9705400129610088, 0.08356587959000603, 0.0656589053921476, 0.8237208131014879, 0.017906974197858434, 0.01193798279857229, 0.19732226897164978, 0.09144202708442307, 0.5245884711685324, 0.07700381228161943, 0.11069298015482792, 0.9880903363149348, 0.11149829889738921, 0.1991041051739093, 0.05574914944869461, 0.03185665682782549, 0.6052764797286844, 0.19505502210251324, 0.29067022901550993, 0.042070691041718546, 0.4551283849058642, 0.01529843310607947, 0.9864267532257209, 0.9786990940106546, 0.4887469614797456, 0.12168801898067136, 0.09176473562476857, 0.1456266456653936, 0.14961641677951396, 0.9751208007382368, 0.9667570334030327, 0.01408613369844644, 0.9719432251928044, 0.986647999392493, 0.9826847373121398, 0.9565396285806492, 0.026570545238351367, 0.026570545238351367, 0.14572592754379476, 0.8452103797540097, 0.9588471821481198, 0.025232820582845258, 0.2415759187746554, 0.37945095534360507, 0.1850118012079068, 0.12609084540921037, 0.06599147049454, 0.010837112078090284, 0.010837112078090284, 0.032511336234270855, 0.9428287507938546, 0.010837112078090284, 0.9920698186658882, 0.7320409388032267, 0.06654917625483879, 0.061619607643369254, 0.07640831347777788, 0.061619607643369254, 0.9844295167448919, 0.02819415935013605, 0.9586014179046256, 0.2733980978648115, 0.2339893630374513, 0.22660022525732126, 0.17733930672312098, 0.08866965336156049, 0.9759699918209345, 0.9620112039296637, 0.008825790861740034, 0.017651581723480067, 0.008825790861740034, 0.008825790861740034, 0.16696133429506163, 0.08026987225724116, 0.49125161821431595, 0.15411815473390306, 0.10916702626984799, 0.9619806979801968, 0.9671431119017271, 0.983583002226658, 0.9900439774893725, 0.9844239562438952, 0.9713129185274042, 0.013926454932518649, 0.006963227466259324, 0.027852909865037297, 0.9469989354112681, 0.006963227466259324, 0.9722489981298649, 0.37297977297234225, 0.2889975724355235, 0.15314401274361072, 0.18031472468199328, 0.002470064721671141, 0.03625716204808151, 0.021754297228848904, 0.014502864819232603, 0.9136804836116539, 0.021754297228848904, 0.8789664629591567, 0.09553983293034313, 0.019107966586068625, 0.9654266692710245, 0.19216615036389328, 0.809843062247836, 0.18766581172793462, 0.3603183585176345, 0.19517244419705201, 0.05629974351838039, 0.1989257604316107, 0.03568339102769275, 0.0285467128221542, 0.9349048449255501, 0.9891020434280619, 0.9804250398687512, 0.016617373557097477, 0.1866311863153469, 0.08428505188435022, 0.06622396933770373, 0.13846829952428963, 0.5237713938527477, 0.9866456657863544, 0.034689621269378836, 0.8094244962855062, 0.034689621269378836, 0.09250565671834356, 0.034689621269378836, 0.03501868329138586, 0.3385139384833966, 0.5252802493707879, 0.005836447215230977, 0.0992196026589266, 0.9855624955471779, 0.9718846639255891, 0.5263185645420607, 0.08606467093140616, 0.09268503023382202, 0.1489580843043568, 0.14233772500194095, 0.9884059788780066, 0.964227783798619, 0.9525333284959229, 0.023707856494967608, 0.972022116293672, 0.01739424277928968, 0.00434856069482242, 0.06522841042233629, 0.9131977459127081, 0.3434354139054444, 0.005539280869442652, 0.6480958617247903, 0.9930291493946767, 0.9934564319459044, 0.9688327919094922, 0.2956050389558233, 0.21376397445152512, 0.24796621036376915, 0.15635307845597265, 0.08672709820604733, 0.97396413037157, 0.6687321645422809, 0.014228343926431509, 0.003557085981607877, 0.30946648039988534, 0.003557085981607877, 0.012079117418873932, 0.012079117418873932, 0.7730635148079317, 0.20534499612085683, 0.9567735478993726, 0.02422211513669298, 0.01211105756834649, 0.023481805691050323, 0.11740902845525161, 0.8609995420051785, 0.7204195953124278, 0.016884834265135026, 0.25890079206540373, 0.15813203191985123, 0.3301006166326894, 0.3123107630417062, 0.14627212952586238, 0.05336956077294979, 0.023649959123218146, 0.9617650043442045, 0.9544155677110502, 0.36562890760548256, 0.1699853693253559, 0.009621813358039013, 0.39449434767959957, 0.05773088014823408, 0.016230227224331237, 0.09738136334598742, 0.016230227224331237, 0.8602020428895555, 0.9820537598886094, 0.9788229661132297, 0.31582047518184003, 0.5148306376251913, 0.008652615758406576, 0.034610463033626304, 0.12546292849689536, 0.2433053401636182, 0.1841592906210812, 0.18281506222238716, 0.2836321921244389, 0.10619404349682784, 0.043875224079967134, 0.19012597101319093, 0.010968806019991784, 0.6983473166061436, 0.05484403009995892, 0.6376440553303239, 0.011437561530588768, 0.15440708066294836, 0.04575024612235507, 0.14868829989765397, 0.973154466442455, 0.29141927951947266, 0.13883654354465444, 0.22956141358373555, 0.32166090286583304, 0.017870050159212947, 0.4267117863892013, 0.20795447817701582, 0.2268594307385627, 0.10532759284290412, 0.035109197614301375, 0.9838063379626059, 0.2093435996419109, 0.07281516509283857, 0.2912606603713543, 0.22936777004244152, 0.1984213248779851, 0.16047865859716748, 0.25441738558087523, 0.446208953172612, 0.1409080904755617, 0.11141596998083728, 0.8754111927065786, 0.015916567140119613, 0.02024053785412491, 0.10120268927062455, 0.10120268927062455, 0.01349369190274994, 0.7623935925053715, 0.8019510252383977, 0.16785021458478092, 0.02797503576413015, 0.0399708356364877, 0.05995625345473155, 0.8993438018209733, 0.08154564691660728, 0.8970021160826801, 0.9032595165069495, 0.0677444637380212, 0.7072581357654326, 0.03022470665664242, 0.01813482399398545, 0.24179765325313937, 0.09326674458894892, 0.03244060681354745, 0.7582991842666716, 0.11354212384741608, 0.004055075851693431, 0.9749302750587554, 0.8008016428823079, 0.030105324920387515, 0.030105324920387515, 0.10235810472931754, 0.03612638990446502, 0.14417662143820326, 0.008480977731659015, 0.025442933194977042, 0.08480977731659015, 0.7463260403859933, 0.19604179950464176, 0.015080138423433982, 0.6409058829959443, 0.10556096896403788, 0.04524041527030195, 0.99383865081951, 0.21626549116606225, 0.1560304718144409, 0.14224173244479263, 0.35270143861310826, 0.13280733182345433, 0.9717142990690641, 0.9929354098134104, 0.5600439364296786, 0.04184236306658518, 0.016093216564071224, 0.31864568796861026, 0.0643728662562849, 0.9913735748391824, 0.9719492439230556, 0.21078029206018875, 0.7935258054030635, 0.20168669861421934, 0.274137260252337, 0.274137260252337, 0.14685924656375196, 0.10182241095086803, 0.008559898090202188, 0.008559898090202188, 0.9758283822830495, 0.9296549796795622, 0.027342793519987123, 0.9908600121573279, 0.2375280152273175, 0.2790954178920981, 0.18052129157276128, 0.13539096867957098, 0.16864489081139541, 0.9890165479061803, 0.9734707683099715, 0.9538122308604864, 0.9734679163213512, 0.10919319217484884, 0.09827387295736395, 0.05459659608742442, 0.7315943875714872, 0.3023005166726075, 0.21592894048043393, 0.06621820841399974, 0.14395262698695593, 0.27063093873547717, 0.10186923672392283, 0.08334755731957322, 0.009260839702174803, 0.8056930540892078, 0.7560893166055155, 0.07875930381307453, 0.07875930381307453, 0.02362779114392236, 0.06300744305045962, 0.9697680837045901, 0.018297511013294153, 0.984441637741967, 0.5035585915427168, 0.062485372673183825, 0.03675610157246107, 0.2425902703782431, 0.1543756266043365, 0.3617979500079319, 0.004889161486593675, 0.14178568311121656, 0.4498028567666181, 0.034224130406155726, 0.10580309346643578, 0.11825051622719293, 0.18048763003097867, 0.056013402423407174, 0.541462890092936, 0.970708552337152, 0.030744322894155116, 0.9684461711658862, 0.09935880198915471, 0.006623920132610314, 0.013247840265220629, 0.8809813776371718, 0.01393359550044511, 0.8499493255271517, 0.125402359504006, 0.014489307154557558, 0.1014251500819029, 0.1014251500819029, 0.777592817294589, 0.004829769051519186, 0.9703159841754143, 0.9735860549729561, 0.016704030539505955, 0.03340806107901191, 0.9354257102123334, 0.020920750622262008, 0.020920750622262008, 0.9065658602980203, 0.041841501244524015, 0.013947167081508005, 0.03302332540269075, 0.9576764366780317, 0.9827035043728272, 0.012511239319805089, 0.5379832907516188, 0.28775850435551703, 0.0563005769391229, 0.10634553421834325, 0.9744887525408515, 0.21547650379718725, 0.15181299131165465, 0.034280352876825244, 0.1958877307247157, 0.40156984798566714, 0.9911333040006284, 0.9781277962944481, 0.00988007875044897, 0.004940039375224485, 0.004940039375224485, 0.6466618041039608, 0.16302398422788927, 0.010868265615192618, 0.17389224984308188, 0.005434132807596309, 0.18775652423737818, 0.061130031147053364, 0.04366430796218097, 0.1702908010525058, 0.5327045571386079, 0.031002954600625136, 0.9610915926193792, 0.4582256847562206, 0.1217161975133711, 0.03579888162157974, 0.34366926356716543, 0.04295865794589568, 0.15004824721761367, 0.23372900047359052, 0.26546997584654725, 0.014427716078616698, 0.3347230130239074, 0.9827967164820106, 0.9597763343688661, 0.024365548158735914, 0.9502563781907007, 0.9488041411517156, 0.02808606806310405, 0.02808606806310405, 0.9549263141455377, 0.2425615179075177, 0.39237892602686686, 0.021402486874192737, 0.1521954622164817, 0.19262238186773464, 0.9563899613658126, 0.9825747270695858, 0.18415085329223363, 0.2935738240890681, 0.18948855918476215, 0.3069180888203894, 0.026688529462642555, 0.3946207946129535, 0.081902429070613, 0.22088836931165323, 0.263080529741969, 0.03971026864029721, 0.9663861471120321, 0.008053217892600268, 0.016106435785200535, 0.008053217892600268, 0.008053217892600268, 0.9821143504207048, 0.00994530916477419, 0.47405973685423636, 0.12265881303221501, 0.24200252300950528, 0.14917963747161284, 0.09309175148510018, 0.12173536732666948, 0.014321807920784644, 0.7733776277223708, 0.9828370747117565, 0.8855123917110308, 0.07906360640277062, 0.03162544256110825, 0.2374482403612523, 0.02316568198646364, 0.3011538658240273, 0.3011538658240273, 0.13754623679462788, 0.9849190705815082, 0.9588881315790897, 0.08015208398573856, 0.0935107646500283, 0.8015208398573855, 0.026717361328579516, 0.023283477366990317, 0.9662643107300981, 0.9898583328560782, 0.9712246760439822, 0.9697761617782146, 0.9902943862102624, 0.9624342710067478, 0.3040549484438339, 0.07705502118097161, 0.15202747422191695, 0.4560824226657509, 0.0104128407001313, 0.0068231611049405505, 0.0068231611049405505, 0.0068231611049405505, 0.9825351991114393, 0.9621653178377386, 0.23794400121891174, 0.5017514808311834, 0.09828121789476789, 0.020690782714687977, 0.13966278332414384, 0.03958855010097704, 0.01979427505048852, 0.8709481022214949, 0.07917710020195408, 0.029657383548049327, 0.9490362735375785, 0.9686190863324463, 0.013783995181897062, 0.9924476530965886, 0.006825009139880555, 0.2593503473154611, 0.006825009139880555, 0.13650018279761109, 0.5937757951696083, 0.06016112508477533, 0.13946442633288825, 0.642630199769191, 0.15587200590146336, 0.9860510181022172, 0.3522804603926896, 0.6186388572749671, 0.008592206351041212, 0.017184412702082423, 0.010122193840508503, 0.9818528025293247, 0.9592061598310959, 0.8375840866093585, 0.07357157517514636, 0.03961546355584804, 0.05093416742894748, 0.13125181533537358, 0.01009629348733643, 0.070674054411355, 0.797607185499578, 0.017839817520238027, 0.9633501460928535, 0.017839817520238027, 0.9896653531828692, 0.8361839467705177, 0.06886220738110145, 0.04426856188785094, 0.049187290986501035, 0.02639083259348741, 0.9500699733655469, 0.9730861186215554, 0.23203471785270413, 0.41933985154103154, 0.13139315348285655, 0.0698899752568386, 0.14816674754449782, 0.4321679583055261, 0.09177311855908857, 0.15851720478388023, 0.2319356996311511, 0.0834301077809896, 0.9632698669397074, 0.2413933490846377, 0.00588764266060092, 0.730067689914514, 0.02355057064240368, 0.979581441397576, 0.12830254822830134, 0.05578371662100058, 0.7865504043561082, 0.022313486648400233, 0.005578371662100058, 0.9843450316664837, 0.19642494522203557, 0.003069139769094306, 0.006138279538188612, 0.030691397690943055, 0.7642158025044821, 0.9707811249709226, 0.17577485526559236, 0.03255089912325784, 0.6119569035172475, 0.06510179824651569, 0.11067305701907668, 0.9589939500765928, 0.9918739689030496, 0.9653434265163665, 0.01719242239839487, 0.01719242239839487, 0.9627756543101129, 0.44700087042058284, 0.16341967305698726, 0.07930660604236148, 0.24272627909934874, 0.0696936840978328, 0.10661208120391912, 0.3553736040130637, 0.29851382737097354, 0.028429888321045097, 0.21322416240783823, 0.9951179608656576, 0.5825129889462267, 0.06377879441017081, 0.029763437391413045, 0.21684790099458076, 0.11054991031096274, 0.7772052551106194, 0.15861331736951417, 0.04758399521085425, 0.9808695378407402, 0.9862297288020334, 0.15467081956239315, 0.3841823582678798, 0.32181509231530186, 0.05488319403826854, 0.08481948169550592, 0.18689438447725548, 0.019673093102868997, 0.5836350953851136, 0.1442693494210393, 0.062298128159085156, 0.15334676029657457, 0.2555779338276243, 0.5529777113724962, 0.03717497219310899, 0.14052229967924015, 0.32621248139823605, 0.13299431933928085, 0.3487964224181139, 0.052695862379715054, 0.8736129843459262, 0.03317517662073138, 0.08846713765528366, 0.2693945794847391, 0.14492746364685333, 0.23529399980312657, 0.1943733041851915, 0.15686266653541772, 0.985876093712812, 0.9790522281318239, 0.09480138110391219, 0.20241375965429897, 0.02049759591435939, 0.008967698212532235, 0.673858465684565, 0.018369853984880613, 0.9736022611986724, 0.009184926992440307, 0.09113359578583818, 0.2681931533126095, 0.39057255336787794, 0.06249160853886047, 0.19007864263903393, 0.307809667780932, 0.21117174882645334, 0.17180074480796206, 0.17001115371621245, 0.13779851406471957, 0.1269576627070543, 0.060456029860502046, 0.6045602986050205, 0.19950489853965675], \"Term\": [\"$\", \"$\", \"$\", \"$\", \"$\", \"18\", \"2016\", \"2016\", \"2016\", \"4\", \"5\", \"7\", \"a-list\", \"abc\", \"abort\", \"access\", \"accord\", \"accord\", \"accord\", \"accord\", \"accord\", \"achiev\", \"across\", \"across\", \"across\", \"activ\", \"actual\", \"actual\", \"actual\", \"actual\", \"actual\", \"advic\", \"advic\", \"advic\", \"agre\", \"allen\", \"allow\", \"allow\", \"along\", \"along\", \"altern\", \"amount\", \"amount\", \"andrew\", \"anim\", \"annual\", \"anxieti\", \"anyon\", \"appl\", \"appli\", \"area\", \"assault\", \"assault\", \"assault\", \"attempt\", \"award\", \"award\", \"award\", \"award\", \"bachelor\", \"bachelor\", \"bachelor\", \"bachelor\", \"back\", \"back\", \"back\", \"back\", \"back\", \"bad\", \"bad\", \"bad\", \"bad\", \"bang\", \"bang\", \"barack\", \"bare\", \"bath\", \"bathroom\", \"beauti\", \"beauti\", \"beauti\", \"beauti\", \"beauti\", \"bella\", \"bella\", \"bella\", \"bernadett\", \"best\", \"best\", \"best\", \"best\", \"best\", \"big\", \"big\", \"big\", \"big\", \"big\", \"blake\", \"blake\", \"blogger\", \"blood\", \"bold\", \"boot\", \"boot\", \"boot\", \"bottom\", \"breakfast\", \"breakup\", \"breakup\", \"bride\", \"bride\", \"bride\", \"bridesmaid\", \"bright\", \"britney\", \"buy\", \"buy\", \"buy\", \"buy\", \"camera\", \"can\", \"can\", \"can\", \"can\", \"can\", \"cancer\", \"cancer\", \"card\", \"card\", \"card\", \"carpet\", \"carpool\", \"celebr\", \"celebr\", \"celebr\", \"celebr\", \"celebr\", \"certain\", \"certain\", \"cheat\", \"citi\", \"citi\", \"citi\", \"citi\", \"citi\", \"clean\", \"clinton\", \"clinton\", \"clinton\", \"coffe\", \"cold\", \"come\", \"come\", \"come\", \"come\", \"come\", \"competit\", \"count\", \"countri\", \"countri\", \"countri\", \"countri\", \"countri\", \"crazi\", \"credit\", \"dark\", \"date\", \"date\", \"date\", \"date\", \"date\", \"day\", \"day\", \"day\", \"day\", \"day\", \"determin\", \"dewan\", \"dinner\", \"dinner\", \"disney\", \"disney\", \"disney\", \"doctor\", \"doctor\", \"dog\", \"don\", \"donald\", \"donald\", \"donald\", \"donald\", \"dr.\", \"dream\", \"dress\", \"dress\", \"dress\", \"dress\", \"dress\", \"earn\", \"elect\", \"elect\", \"elect\", \"elect\", \"elimin\", \"employ\", \"employe\", \"employe\", \"engag\", \"engag\", \"engag\", \"engag\", \"engag\", \"epic\", \"especi\", \"even\", \"even\", \"even\", \"even\", \"even\", \"everi\", \"everi\", \"everi\", \"everi\", \"everi\", \"expert\", \"expert\", \"expert\", \"expert\", \"extra\", \"fall\", \"fall\", \"fall\", \"fall\", \"fall\", \"favorit\", \"favorit\", \"favorit\", \"favorit\", \"favorit\", \"feet\", \"femal\", \"femal\", \"femal\", \"femal\", \"femal\", \"final\", \"final\", \"final\", \"final\", \"final\", \"financi\", \"fine\", \"first\", \"first\", \"first\", \"first\", \"first\", \"fletcher\", \"florida\", \"food\", \"food\", \"fox\", \"gain\", \"gala\", \"gala\", \"gala\", \"gender\", \"gender\", \"generat\", \"generat\", \"get\", \"get\", \"get\", \"get\", \"get\", \"gigi\", \"gigi\", \"gigi\", \"gigi\", \"gigi\", \"gilmor\", \"girl\", \"girl\", \"girl\", \"girl\", \"girl\", \"globe\", \"glow\", \"glow\", \"go\", \"go\", \"go\", \"go\", \"go\", \"golden\", \"gomez\", \"gomez\", \"gomez\", \"gomez\", \"gomez\", \"good\", \"good\", \"good\", \"good\", \"good\", \"googl\", \"green\", \"grey\", \"gun\", \"gwen\", \"gym\", \"hadid\", \"hadid\", \"hadid\", \"hadid\", \"hadid\", \"hailey\", \"hair\", \"hair\", \"hair\", \"hair\", \"hair\", \"harri\", \"harri\", \"harri\", \"harri\", \"harri\", \"health\", \"health\", \"health\", \"healthi\", \"heard\", \"heard\", \"help\", \"help\", \"help\", \"help\", \"help\", \"hillari\", \"hillari\", \"hillari\", \"hire\", \"hour\", \"hour\", \"hous\", \"hous\", \"hous\", \"hous\", \"hous\", \"howev\", \"http\", \"http\", \"http\", \"http\", \"http\", \"idea\", \"idea\", \"idea\", \"idea\", \"idea\", \"impress\", \"ingredi\", \"instagram\", \"instagram\", \"instagram\", \"instagram\", \"instagram\", \"invest\", \"isn\", \"j.k.\", \"jenna\", \"jenna\", \"jenner\", \"jenner\", \"jenner\", \"jenner\", \"job\", \"job\", \"job\", \"jojo\", \"journey\", \"judg\", \"just\", \"just\", \"just\", \"just\", \"just\", \"karaok\", \"kardashian\", \"kardashian\", \"kardashian\", \"kardashian\", \"kardashian\", \"kate\", \"kate\", \"kate\", \"kate\", \"kati\", \"kati\", \"kati\", \"kendal\", \"kendal\", \"kendal\", \"kim\", \"kim\", \"kim\", \"know\", \"know\", \"know\", \"know\", \"know\", \"kyli\", \"kyli\", \"la\", \"last\", \"last\", \"last\", \"last\", \"last\", \"law\", \"law\", \"law\", \"law\", \"lemonad\", \"liar\", \"life\", \"life\", \"life\", \"life\", \"life\", \"like\", \"like\", \"like\", \"like\", \"like\", \"littl\", \"littl\", \"littl\", \"littl\", \"littl\", \"live\", \"live\", \"live\", \"live\", \"live\", \"locat\", \"look\", \"look\", \"look\", \"look\", \"look\", \"love\", \"love\", \"love\", \"love\", \"love\", \"luna\", \"make\", \"make\", \"make\", \"make\", \"make\", \"makeup\", \"makeup\", \"makeup\", \"makeup\", \"mayb\", \"mayb\", \"mayb\", \"men\", \"men\", \"men\", \"men\", \"men\", \"met\", \"met\", \"met\", \"michell\", \"michell\", \"michell\", \"millenni\", \"millenni\", \"minut\", \"minut\", \"moment\", \"moment\", \"moment\", \"moment\", \"movi\", \"movi\", \"movi\", \"movi\", \"movi\", \"mtv\", \"music\", \"music\", \"music\", \"music\", \"music\", \"nation\", \"nation\", \"nation\", \"nation\", \"nation\", \"netflix\", \"netflix\", \"netflix\", \"netflix\", \"netflix\", \"network\", \"new\", \"new\", \"new\", \"new\", \"new\", \"newli\", \"nice\", \"night\", \"night\", \"night\", \"night\", \"night\", \"nine\", \"nomin\", \"noth\", \"noth\", \"now\", \"now\", \"now\", \"now\", \"now\", \"obama\", \"obama\", \"obama\", \"obvious\", \"obvious\", \"olymp\", \"one\", \"one\", \"one\", \"one\", \"one\", \"orang\", \"paid\", \"paper\", \"pass\", \"pay\", \"pay\", \"pay\", \"pay\", \"peopl\", \"peopl\", \"peopl\", \"peopl\", \"peopl\", \"percent\", \"percent\", \"percent\", \"percent\", \"perform\", \"perform\", \"perform\", \"perform\", \"perform\", \"perri\", \"perri\", \"phone\", \"photo\", \"photo\", \"photo\", \"photo\", \"photo\", \"pictur\", \"pictur\", \"pictur\", \"pictur\", \"pictur\", \"plan\", \"plan\", \"plan\", \"plan\", \"plan\", \"polish\", \"potter\", \"potter\", \"presid\", \"presid\", \"presid\", \"presid\", \"presidenti\", \"presidenti\", \"presidenti\", \"pretti\", \"pretti\", \"pretti\", \"pretti\", \"pretti\", \"prevent\", \"primari\", \"princ\", \"princ\", \"princ\", \"product\", \"product\", \"product\", \"product\", \"product\", \"rate\", \"rate\", \"rather\", \"real\", \"real\", \"real\", \"real\", \"real\", \"realiz\", \"recent\", \"recent\", \"recent\", \"recent\", \"recent\", \"recip\", \"red\", \"red\", \"red\", \"red\", \"relationship\", \"relationship\", \"relationship\", \"relationship\", \"relationship\", \"report\", \"report\", \"report\", \"report\", \"report\", \"republican\", \"republican\", \"reveal\", \"reveal\", \"reveal\", \"reveal\", \"reveal\", \"right\", \"right\", \"right\", \"right\", \"right\", \"rob\", \"rowl\", \"sale\", \"sale\", \"san\", \"sarah\", \"sarah\", \"sarah\", \"say\", \"say\", \"say\", \"say\", \"say\", \"scent\", \"search\", \"season\", \"season\", \"season\", \"season\", \"season\", \"see\", \"see\", \"see\", \"see\", \"see\", \"selena\", \"selena\", \"selena\", \"selena\", \"selena\", \"sell\", \"sex\", \"sex\", \"sex\", \"sex\", \"sex\", \"sexual\", \"sexual\", \"sexual\", \"sexual\", \"sheldon\", \"shop\", \"shop\", \"shop\", \"show\", \"show\", \"show\", \"show\", \"show\", \"signific\", \"simon\", \"skin\", \"skin\", \"skin\", \"skin\", \"snapchat\", \"snapchat\", \"sometim\", \"south\", \"spear\", \"spice\", \"sport\", \"star\", \"star\", \"star\", \"star\", \"star\", \"state\", \"state\", \"state\", \"state\", \"stefani\", \"stori\", \"stori\", \"stori\", \"stori\", \"stori\", \"stream\", \"stream\", \"stream\", \"stream\", \"stress\", \"stress\", \"stretch\", \"student\", \"student\", \"studi\", \"studi\", \"studi\", \"studi\", \"studi\", \"summer\", \"summer\", \"summer\", \"summer\", \"sun\", \"sure\", \"sure\", \"sure\", \"sure\", \"survey\", \"survey\", \"surviv\", \"swift\", \"swift\", \"swift\", \"swift\", \"tattoo\", \"tattoo\", \"tattoo\", \"tattoo\", \"tatum\", \"tatum\", \"tatum\", \"tax\", \"taylor\", \"taylor\", \"taylor\", \"taylor\", \"tear\", \"tear\", \"tend\", \"thing\", \"thing\", \"thing\", \"thing\", \"thing\", \"time\", \"time\", \"time\", \"time\", \"time\", \"toni\", \"top\", \"top\", \"top\", \"top\", \"tough\", \"trend\", \"trend\", \"trend\", \"trend\", \"trend\", \"truli\", \"trump\", \"trump\", \"trump\", \"trump\", \"trump\", \"truth\", \"tv\", \"tv\", \"tv\", \"tv\", \"tv\", \"ugli\", \"ultim\", \"unicorn\", \"unit\", \"unit\", \"unit\", \"us\", \"us\", \"us\", \"us\", \"us\", \"use\", \"use\", \"use\", \"use\", \"use\", \"vagina\", \"video\", \"video\", \"video\", \"video\", \"video\", \"vote\", \"vote\", \"vote\", \"voter\", \"wall\", \"way\", \"way\", \"way\", \"way\", \"way\", \"wear\", \"wear\", \"wear\", \"wear\", \"wear\", \"wed\", \"wed\", \"wed\", \"wed\", \"week\", \"week\", \"week\", \"week\", \"week\", \"west\", \"west\", \"west\", \"will\", \"will\", \"will\", \"will\", \"will\", \"winner\", \"within\", \"women\", \"women\", \"women\", \"women\", \"women\", \"wonder\", \"wonder\", \"wonder\", \"work\", \"work\", \"work\", \"work\", \"work\", \"year\", \"year\", \"year\", \"year\", \"year\", \"york\", \"york\", \"york\", \"york\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [1, 2, 4, 3, 5]};\n",
       "\n",
       "function LDAvis_load_lib(url, callback){\n",
       "  var s = document.createElement('script');\n",
       "  s.src = url;\n",
       "  s.async = true;\n",
       "  s.onreadystatechange = s.onload = callback;\n",
       "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
       "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "}\n",
       "\n",
       "if(typeof(LDAvis) !== \"undefined\"){\n",
       "   // already loaded: just create the visualization\n",
       "   !function(LDAvis){\n",
       "       new LDAvis(\"#\" + \"ldavis_el3913106031220243521416100\", ldavis_el3913106031220243521416100_data);\n",
       "   }(LDAvis);\n",
       "}else if(typeof define === \"function\" && define.amd){\n",
       "   // require.js is available: use it to load d3/LDAvis\n",
       "   require.config({paths: {d3: \"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min\"}});\n",
       "   require([\"d3\"], function(d3){\n",
       "      window.d3 = d3;\n",
       "      LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
       "        new LDAvis(\"#\" + \"ldavis_el3913106031220243521416100\", ldavis_el3913106031220243521416100_data);\n",
       "      });\n",
       "    });\n",
       "}else{\n",
       "    // require.js not available: dynamically load d3 & LDAvis\n",
       "    LDAvis_load_lib(\"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min.js\", function(){\n",
       "         LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
       "                 new LDAvis(\"#\" + \"ldavis_el3913106031220243521416100\", ldavis_el3913106031220243521416100_data);\n",
       "            })\n",
       "         });\n",
       "}\n",
       "</script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glamour_vis = pyLDAvis.gensim.prepare(glamour_ldamodel, glamour_corpus, glamour_dictionary)\n",
    "pyLDAvis.display(glamour_vis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 20 tf-idf:\n",
      "new          6982\n",
      "best         4277\n",
      "beauty       2874\n",
      "fashion      2713\n",
      "hair         2401\n",
      "2017         2246\n",
      "trump        2210\n",
      "2016         2209\n",
      "just         2061\n",
      "jenner       2014\n",
      "instagram    1907\n",
      "makeup       1693\n",
      "week         1634\n",
      "style        1602\n",
      "10           1592\n",
      "hadid        1520\n",
      "women        1516\n",
      "look         1500\n",
      "like         1460\n",
      "day          1314\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "tvec20 = CountVectorizer(max_features = 20,stop_words='english')\n",
    "tfidf20  = pd.DataFrame(tvec20.fit_transform(blogs.title).todense(),columns=tvec20.get_feature_names())\n",
    "print(\"Top 20 tf-idf:\")\n",
    "print(tfidf20.sum().sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 40 tf-idf:\n",
      "new           6982\n",
      "best          4277\n",
      "beauty        2874\n",
      "fashion       2713\n",
      "hair          2401\n",
      "2017          2246\n",
      "trump         2210\n",
      "2016          2209\n",
      "just          2061\n",
      "jenner        2014\n",
      "instagram     1907\n",
      "makeup        1693\n",
      "week          1634\n",
      "style         1602\n",
      "10            1592\n",
      "hadid         1520\n",
      "women         1516\n",
      "look          1500\n",
      "like          1460\n",
      "day           1314\n",
      "know          1195\n",
      "world         1186\n",
      "summer        1173\n",
      "taylor        1173\n",
      "york          1168\n",
      "kendall       1156\n",
      "video         1155\n",
      "home          1124\n",
      "year          1109\n",
      "kylie         1099\n",
      "looks         1095\n",
      "red           1072\n",
      "donald        1056\n",
      "fall          1016\n",
      "make          1012\n",
      "swift          990\n",
      "gigi           981\n",
      "kardashian     979\n",
      "music          967\n",
      "season         967\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "tvec40 = CountVectorizer(max_features = 40,stop_words='english')\n",
    "tfidf40  = pd.DataFrame(tvec40.fit_transform(blogs.title).todense(),columns=tvec40.get_feature_names())\n",
    "print(\"Top 40 tf-idf:\")\n",
    "print(tfidf40.sum().sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 40 Most Used Words:\n",
      "new           25744\n",
      "like          21982\n",
      "vogue         16995\n",
      "just          16883\n",
      "post          14868\n",
      "fashion       14191\n",
      "appeared      13790\n",
      "look          12096\n",
      "time          12025\n",
      "year          10384\n",
      "best           9884\n",
      "people         9079\n",
      "says           8762\n",
      "day            8183\n",
      "way            8058\n",
      "style          7952\n",
      "really         7771\n",
      "women          7406\n",
      "make           7274\n",
      "week           7254\n",
      "hair           7251\n",
      "beauty         7214\n",
      "think          7158\n",
      "york           6988\n",
      "don            6880\n",
      "world          6791\n",
      "said           6756\n",
      "love           6736\n",
      "ve             6659\n",
      "know           6456\n",
      "years          6453\n",
      "available      6003\n",
      "night          5986\n",
      "life           5628\n",
      "old            5622\n",
      "work           5604\n",
      "collection     5535\n",
      "red            5469\n",
      "instagram      5464\n",
      "season         5439\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "cvec40 = CountVectorizer(max_features = 40,stop_words='english')\n",
    "vec40  = pd.DataFrame(cvec40.fit_transform(blogs.summary).todense(),columns=cvec40.get_feature_names())\n",
    "print(\"Top 40 Most Used Words:\")\n",
    "print(vec40.sum().sort_values(ascending=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
